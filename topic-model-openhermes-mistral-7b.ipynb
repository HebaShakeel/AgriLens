{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11386360,"sourceType":"datasetVersion","datasetId":7129997}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-23T04:18:45.352190Z","iopub.execute_input":"2025-04-23T04:18:45.352397Z","iopub.status.idle":"2025-04-23T04:18:47.124604Z","shell.execute_reply.started":"2025-04-23T04:18:45.352379Z","shell.execute_reply":"2025-04-23T04:18:47.123793Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/agriculture-data/cleaned_text_data.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# GPU-accelerated HDBSCAN + UMAP\n!pip install cudf-cu12 dask-cudf-cu12 --extra-index-url=https://pypi.nvidia.com\n!pip install cuml-cu12 --extra-index-url=https://pypi.nvidia.com\n!pip install cugraph-cu12 --extra-index-url=https://pypi.nvidia.com\n!pip install cupy-cuda12x -f https://pip.cupy.dev/aarch64","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T04:18:56.958740Z","iopub.execute_input":"2025-04-23T04:18:56.959002Z","iopub.status.idle":"2025-04-23T04:21:10.008405Z","shell.execute_reply.started":"2025-04-23T04:18:56.958980Z","shell.execute_reply":"2025-04-23T04:21:10.007619Z"}},"outputs":[{"name":"stdout","text":"Looking in indexes: https://pypi.org/simple, https://pypi.nvidia.com\nRequirement already satisfied: cudf-cu12 in /usr/local/lib/python3.11/dist-packages (25.2.2)\nRequirement already satisfied: dask-cudf-cu12 in /usr/local/lib/python3.11/dist-packages (25.2.2)\nRequirement already satisfied: cachetools in /usr/local/lib/python3.11/dist-packages (from cudf-cu12) (5.5.2)\nRequirement already satisfied: cuda-python<13.0a0,>=12.6.2 in /usr/local/lib/python3.11/dist-packages (from cudf-cu12) (12.8.0)\nRequirement already satisfied: cupy-cuda12x>=12.0.0 in /usr/local/lib/python3.11/dist-packages (from cudf-cu12) (13.4.1)\nRequirement already satisfied: fsspec>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from cudf-cu12) (2025.3.2)\nRequirement already satisfied: libcudf-cu12==25.2.* in /usr/local/lib/python3.11/dist-packages (from cudf-cu12) (25.2.2)\nRequirement already satisfied: numba-cuda<0.3.0a0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from cudf-cu12) (0.2.0)\nRequirement already satisfied: numba<0.61.0a0,>=0.59.1 in /usr/local/lib/python3.11/dist-packages (from cudf-cu12) (0.60.0)\nRequirement already satisfied: numpy<3.0a0,>=1.23 in /usr/local/lib/python3.11/dist-packages (from cudf-cu12) (1.26.4)\nRequirement already satisfied: nvtx>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from cudf-cu12) (0.2.11)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from cudf-cu12) (24.2)\nRequirement already satisfied: pandas<2.2.4dev0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from cudf-cu12) (2.2.3)\nRequirement already satisfied: pyarrow<20.0.0a0,>=14.0.0 in /usr/local/lib/python3.11/dist-packages (from cudf-cu12) (19.0.1)\nRequirement already satisfied: pylibcudf-cu12==25.2.* in /usr/local/lib/python3.11/dist-packages (from cudf-cu12) (25.2.2)\nRequirement already satisfied: pynvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from cudf-cu12) (0.5.2)\nRequirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from cudf-cu12) (14.0.0)\nRequirement already satisfied: rmm-cu12==25.2.* in /usr/local/lib/python3.11/dist-packages (from cudf-cu12) (25.2.0)\nRequirement already satisfied: typing_extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from cudf-cu12) (4.13.1)\nRequirement already satisfied: libkvikio-cu12==25.2.* in /usr/local/lib/python3.11/dist-packages (from libcudf-cu12==25.2.*->cudf-cu12) (25.2.1)\nRequirement already satisfied: nvidia-nvcomp-cu12==4.2.0.11 in /usr/local/lib/python3.11/dist-packages (from libcudf-cu12==25.2.*->cudf-cu12) (4.2.0.11)\nRequirement already satisfied: pynvml<13.0.0a0,>=12.0.0 in /usr/local/lib/python3.11/dist-packages (from dask-cudf-cu12) (12.0.0)\nRequirement already satisfied: rapids-dask-dependency==25.2.* in /usr/local/lib/python3.11/dist-packages (from dask-cudf-cu12) (25.2.0)\nRequirement already satisfied: dask==2024.12.1 in /usr/local/lib/python3.11/dist-packages (from rapids-dask-dependency==25.2.*->dask-cudf-cu12) (2024.12.1)\nRequirement already satisfied: distributed==2024.12.1 in /usr/local/lib/python3.11/dist-packages (from rapids-dask-dependency==25.2.*->dask-cudf-cu12) (2024.12.1)\nRequirement already satisfied: dask-expr==1.1.21 in /usr/local/lib/python3.11/dist-packages (from rapids-dask-dependency==25.2.*->dask-cudf-cu12) (1.1.21)\nRequirement already satisfied: click>=8.1 in /usr/local/lib/python3.11/dist-packages (from dask==2024.12.1->rapids-dask-dependency==25.2.*->dask-cudf-cu12) (8.1.8)\nRequirement already satisfied: cloudpickle>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from dask==2024.12.1->rapids-dask-dependency==25.2.*->dask-cudf-cu12) (3.1.1)\nRequirement already satisfied: partd>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from dask==2024.12.1->rapids-dask-dependency==25.2.*->dask-cudf-cu12) (1.4.2)\nRequirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from dask==2024.12.1->rapids-dask-dependency==25.2.*->dask-cudf-cu12) (6.0.2)\nRequirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from dask==2024.12.1->rapids-dask-dependency==25.2.*->dask-cudf-cu12) (1.0.0)\nRequirement already satisfied: importlib_metadata>=4.13.0 in /usr/local/lib/python3.11/dist-packages (from dask==2024.12.1->rapids-dask-dependency==25.2.*->dask-cudf-cu12) (8.6.1)\nRequirement already satisfied: jinja2>=2.10.3 in /usr/local/lib/python3.11/dist-packages (from distributed==2024.12.1->rapids-dask-dependency==25.2.*->dask-cudf-cu12) (3.1.6)\nRequirement already satisfied: locket>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from distributed==2024.12.1->rapids-dask-dependency==25.2.*->dask-cudf-cu12) (1.0.0)\nRequirement already satisfied: msgpack>=1.0.2 in /usr/local/lib/python3.11/dist-packages (from distributed==2024.12.1->rapids-dask-dependency==25.2.*->dask-cudf-cu12) (1.1.0)\nRequirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from distributed==2024.12.1->rapids-dask-dependency==25.2.*->dask-cudf-cu12) (7.0.0)\nRequirement already satisfied: sortedcontainers>=2.0.5 in /usr/local/lib/python3.11/dist-packages (from distributed==2024.12.1->rapids-dask-dependency==25.2.*->dask-cudf-cu12) (2.4.0)\nRequirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from distributed==2024.12.1->rapids-dask-dependency==25.2.*->dask-cudf-cu12) (3.1.0)\nRequirement already satisfied: tornado>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from distributed==2024.12.1->rapids-dask-dependency==25.2.*->dask-cudf-cu12) (6.4.2)\nRequirement already satisfied: urllib3>=1.26.5 in /usr/local/lib/python3.11/dist-packages (from distributed==2024.12.1->rapids-dask-dependency==25.2.*->dask-cudf-cu12) (2.3.0)\nRequirement already satisfied: zict>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from distributed==2024.12.1->rapids-dask-dependency==25.2.*->dask-cudf-cu12) (3.0.0)\nRequirement already satisfied: cuda-bindings~=12.8.0 in /usr/local/lib/python3.11/dist-packages (from cuda-python<13.0a0,>=12.6.2->cudf-cu12) (12.8.0)\nRequirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.11/dist-packages (from cupy-cuda12x>=12.0.0->cudf-cu12) (0.8.3)\nRequirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba<0.61.0a0,>=0.59.1->cudf-cu12) (0.43.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3.0a0,>=1.23->cudf-cu12) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3.0a0,>=1.23->cudf-cu12) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3.0a0,>=1.23->cudf-cu12) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3.0a0,>=1.23->cudf-cu12) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3.0a0,>=1.23->cudf-cu12) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3.0a0,>=1.23->cudf-cu12) (2.4.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<2.2.4dev0,>=2.0->cudf-cu12) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<2.2.4dev0,>=2.0->cudf-cu12) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<2.2.4dev0,>=2.0->cudf-cu12) (2025.2)\nRequirement already satisfied: nvidia-ml-py<13.0.0a0,>=12.0.0 in /usr/local/lib/python3.11/dist-packages (from pynvml<13.0.0a0,>=12.0.0->dask-cudf-cu12) (12.570.86)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->cudf-cu12) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->cudf-cu12) (2.19.1)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->cudf-cu12) (0.1.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<2.2.4dev0,>=2.0->cudf-cu12) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0a0,>=1.23->cudf-cu12) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0a0,>=1.23->cudf-cu12) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3.0a0,>=1.23->cudf-cu12) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3.0a0,>=1.23->cudf-cu12) (2024.2.0)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata>=4.13.0->dask==2024.12.1->rapids-dask-dependency==25.2.*->dask-cudf-cu12) (3.21.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3.0a0,>=1.23->cudf-cu12) (2024.2.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2>=2.10.3->distributed==2024.12.1->rapids-dask-dependency==25.2.*->dask-cudf-cu12) (3.0.2)\nLooking in indexes: https://pypi.org/simple, https://pypi.nvidia.com\nRequirement already satisfied: cuml-cu12 in /usr/local/lib/python3.11/dist-packages (25.2.1)\nRequirement already satisfied: cuda-python<13.0a0,>=12.6.2 in /usr/local/lib/python3.11/dist-packages (from cuml-cu12) (12.8.0)\nRequirement already satisfied: cudf-cu12==25.2.* in /usr/local/lib/python3.11/dist-packages (from cuml-cu12) (25.2.2)\nRequirement already satisfied: cupy-cuda12x>=12.0.0 in /usr/local/lib/python3.11/dist-packages (from cuml-cu12) (13.4.1)\nRequirement already satisfied: cuvs-cu12==25.2.* in /usr/local/lib/python3.11/dist-packages (from cuml-cu12) (25.2.1)\nRequirement already satisfied: dask-cuda==25.2.* in /usr/local/lib/python3.11/dist-packages (from cuml-cu12) (25.2.0)\nRequirement already satisfied: dask-cudf-cu12==25.2.* in /usr/local/lib/python3.11/dist-packages (from cuml-cu12) (25.2.2)\nRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.11/dist-packages (from cuml-cu12) (1.4.2)\nRequirement already satisfied: libcuml-cu12==25.2.* in /usr/local/lib/python3.11/dist-packages (from cuml-cu12) (25.2.1)\nRequirement already satisfied: numba<0.61.0a0,>=0.59.1 in /usr/local/lib/python3.11/dist-packages (from cuml-cu12) (0.60.0)\nRequirement already satisfied: numpy<3.0a0,>=1.23 in /usr/local/lib/python3.11/dist-packages (from cuml-cu12) (1.26.4)\nRequirement already satisfied: nvidia-cublas-cu12 in /usr/local/lib/python3.11/dist-packages (from cuml-cu12) (12.8.4.1)\nRequirement already satisfied: nvidia-cufft-cu12 in /usr/local/lib/python3.11/dist-packages (from cuml-cu12) (11.3.3.83)\nRequirement already satisfied: nvidia-curand-cu12 in /usr/local/lib/python3.11/dist-packages (from cuml-cu12) (10.3.9.90)\nRequirement already satisfied: nvidia-cusolver-cu12 in /usr/local/lib/python3.11/dist-packages (from cuml-cu12) (11.7.3.90)\nRequirement already satisfied: nvidia-cusparse-cu12 in /usr/local/lib/python3.11/dist-packages (from cuml-cu12) (12.5.8.93)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from cuml-cu12) (24.2)\nRequirement already satisfied: pylibraft-cu12==25.2.* in /usr/local/lib/python3.11/dist-packages (from cuml-cu12) (25.2.0)\nRequirement already satisfied: raft-dask-cu12==25.2.* in /usr/local/lib/python3.11/dist-packages (from cuml-cu12) (25.2.0)\nRequirement already satisfied: rapids-dask-dependency==25.2.* in /usr/local/lib/python3.11/dist-packages (from cuml-cu12) (25.2.0)\nRequirement already satisfied: rmm-cu12==25.2.* in /usr/local/lib/python3.11/dist-packages (from cuml-cu12) (25.2.0)\nRequirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from cuml-cu12) (1.15.2)\nRequirement already satisfied: treelite==4.4.1 in /usr/local/lib/python3.11/dist-packages (from cuml-cu12) (4.4.1)\nRequirement already satisfied: cachetools in /usr/local/lib/python3.11/dist-packages (from cudf-cu12==25.2.*->cuml-cu12) (5.5.2)\nRequirement already satisfied: fsspec>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from cudf-cu12==25.2.*->cuml-cu12) (2025.3.2)\nRequirement already satisfied: libcudf-cu12==25.2.* in /usr/local/lib/python3.11/dist-packages (from cudf-cu12==25.2.*->cuml-cu12) (25.2.2)\nRequirement already satisfied: numba-cuda<0.3.0a0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from cudf-cu12==25.2.*->cuml-cu12) (0.2.0)\nRequirement already satisfied: nvtx>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from cudf-cu12==25.2.*->cuml-cu12) (0.2.11)\nRequirement already satisfied: pandas<2.2.4dev0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from cudf-cu12==25.2.*->cuml-cu12) (2.2.3)\nRequirement already satisfied: pyarrow<20.0.0a0,>=14.0.0 in /usr/local/lib/python3.11/dist-packages (from cudf-cu12==25.2.*->cuml-cu12) (19.0.1)\nRequirement already satisfied: pylibcudf-cu12==25.2.* in /usr/local/lib/python3.11/dist-packages (from cudf-cu12==25.2.*->cuml-cu12) (25.2.2)\nRequirement already satisfied: pynvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from cudf-cu12==25.2.*->cuml-cu12) (0.5.2)\nRequirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from cudf-cu12==25.2.*->cuml-cu12) (14.0.0)\nRequirement already satisfied: typing_extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from cudf-cu12==25.2.*->cuml-cu12) (4.13.1)\nRequirement already satisfied: libcuvs-cu12==25.2.* in /usr/local/lib/python3.11/dist-packages (from cuvs-cu12==25.2.*->cuml-cu12) (25.2.1)\nRequirement already satisfied: click>=8.1 in /usr/local/lib/python3.11/dist-packages (from dask-cuda==25.2.*->cuml-cu12) (8.1.8)\nRequirement already satisfied: pynvml<13.0.0a0,>=12.0.0 in /usr/local/lib/python3.11/dist-packages (from dask-cuda==25.2.*->cuml-cu12) (12.0.0)\nRequirement already satisfied: zict>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from dask-cuda==25.2.*->cuml-cu12) (3.0.0)\nRequirement already satisfied: libraft-cu12==25.2.* in /usr/local/lib/python3.11/dist-packages (from libcuml-cu12==25.2.*->cuml-cu12) (25.2.0)\nRequirement already satisfied: distributed-ucxx-cu12==0.42.* in /usr/local/lib/python3.11/dist-packages (from raft-dask-cu12==25.2.*->cuml-cu12) (0.42.0)\nRequirement already satisfied: ucx-py-cu12==0.42.* in /usr/local/lib/python3.11/dist-packages (from raft-dask-cu12==25.2.*->cuml-cu12) (0.42.0)\nRequirement already satisfied: dask==2024.12.1 in /usr/local/lib/python3.11/dist-packages (from rapids-dask-dependency==25.2.*->cuml-cu12) (2024.12.1)\nRequirement already satisfied: distributed==2024.12.1 in /usr/local/lib/python3.11/dist-packages (from rapids-dask-dependency==25.2.*->cuml-cu12) (2024.12.1)\nRequirement already satisfied: dask-expr==1.1.21 in /usr/local/lib/python3.11/dist-packages (from rapids-dask-dependency==25.2.*->cuml-cu12) (1.1.21)\nRequirement already satisfied: cloudpickle>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from dask==2024.12.1->rapids-dask-dependency==25.2.*->cuml-cu12) (3.1.1)\nRequirement already satisfied: partd>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from dask==2024.12.1->rapids-dask-dependency==25.2.*->cuml-cu12) (1.4.2)\nRequirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from dask==2024.12.1->rapids-dask-dependency==25.2.*->cuml-cu12) (6.0.2)\nRequirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from dask==2024.12.1->rapids-dask-dependency==25.2.*->cuml-cu12) (1.0.0)\nRequirement already satisfied: importlib_metadata>=4.13.0 in /usr/local/lib/python3.11/dist-packages (from dask==2024.12.1->rapids-dask-dependency==25.2.*->cuml-cu12) (8.6.1)\nRequirement already satisfied: jinja2>=2.10.3 in /usr/local/lib/python3.11/dist-packages (from distributed==2024.12.1->rapids-dask-dependency==25.2.*->cuml-cu12) (3.1.6)\nRequirement already satisfied: locket>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from distributed==2024.12.1->rapids-dask-dependency==25.2.*->cuml-cu12) (1.0.0)\nRequirement already satisfied: msgpack>=1.0.2 in /usr/local/lib/python3.11/dist-packages (from distributed==2024.12.1->rapids-dask-dependency==25.2.*->cuml-cu12) (1.1.0)\nRequirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from distributed==2024.12.1->rapids-dask-dependency==25.2.*->cuml-cu12) (7.0.0)\nRequirement already satisfied: sortedcontainers>=2.0.5 in /usr/local/lib/python3.11/dist-packages (from distributed==2024.12.1->rapids-dask-dependency==25.2.*->cuml-cu12) (2.4.0)\nRequirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from distributed==2024.12.1->rapids-dask-dependency==25.2.*->cuml-cu12) (3.1.0)\nRequirement already satisfied: tornado>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from distributed==2024.12.1->rapids-dask-dependency==25.2.*->cuml-cu12) (6.4.2)\nRequirement already satisfied: urllib3>=1.26.5 in /usr/local/lib/python3.11/dist-packages (from distributed==2024.12.1->rapids-dask-dependency==25.2.*->cuml-cu12) (2.3.0)\nRequirement already satisfied: ucxx-cu12==0.42.* in /usr/local/lib/python3.11/dist-packages (from distributed-ucxx-cu12==0.42.*->raft-dask-cu12==25.2.*->cuml-cu12) (0.42.0)\nRequirement already satisfied: libkvikio-cu12==25.2.* in /usr/local/lib/python3.11/dist-packages (from libcudf-cu12==25.2.*->cudf-cu12==25.2.*->cuml-cu12) (25.2.1)\nRequirement already satisfied: nvidia-nvcomp-cu12==4.2.0.11 in /usr/local/lib/python3.11/dist-packages (from libcudf-cu12==25.2.*->cudf-cu12==25.2.*->cuml-cu12) (4.2.0.11)\nRequirement already satisfied: libucx-cu12<1.19,>=1.15.0 in /usr/local/lib/python3.11/dist-packages (from ucx-py-cu12==0.42.*->raft-dask-cu12==25.2.*->cuml-cu12) (1.18.0)\nRequirement already satisfied: libucxx-cu12==0.42.* in /usr/local/lib/python3.11/dist-packages (from ucxx-cu12==0.42.*->distributed-ucxx-cu12==0.42.*->raft-dask-cu12==25.2.*->cuml-cu12) (0.42.0)\nRequirement already satisfied: cuda-bindings~=12.8.0 in /usr/local/lib/python3.11/dist-packages (from cuda-python<13.0a0,>=12.6.2->cuml-cu12) (12.8.0)\nRequirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.11/dist-packages (from cupy-cuda12x>=12.0.0->cuml-cu12) (0.8.3)\nRequirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba<0.61.0a0,>=0.59.1->cuml-cu12) (0.43.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3.0a0,>=1.23->cuml-cu12) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3.0a0,>=1.23->cuml-cu12) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3.0a0,>=1.23->cuml-cu12) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3.0a0,>=1.23->cuml-cu12) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3.0a0,>=1.23->cuml-cu12) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3.0a0,>=1.23->cuml-cu12) (2.4.1)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cufft-cu12->cuml-cu12) (12.8.93)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<2.2.4dev0,>=2.0->cudf-cu12==25.2.*->cuml-cu12) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<2.2.4dev0,>=2.0->cudf-cu12==25.2.*->cuml-cu12) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<2.2.4dev0,>=2.0->cudf-cu12==25.2.*->cuml-cu12) (2025.2)\nRequirement already satisfied: nvidia-ml-py<13.0.0a0,>=12.0.0 in /usr/local/lib/python3.11/dist-packages (from pynvml<13.0.0a0,>=12.0.0->dask-cuda==25.2.*->cuml-cu12) (12.570.86)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0a0,>=1.23->cuml-cu12) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0a0,>=1.23->cuml-cu12) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3.0a0,>=1.23->cuml-cu12) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3.0a0,>=1.23->cuml-cu12) (2024.2.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->cudf-cu12==25.2.*->cuml-cu12) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->cudf-cu12==25.2.*->cuml-cu12) (2.19.1)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata>=4.13.0->dask==2024.12.1->rapids-dask-dependency==25.2.*->cuml-cu12) (3.21.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3.0a0,>=1.23->cuml-cu12) (2024.2.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2>=2.10.3->distributed==2024.12.1->rapids-dask-dependency==25.2.*->cuml-cu12) (3.0.2)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->cudf-cu12==25.2.*->cuml-cu12) (0.1.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<2.2.4dev0,>=2.0->cudf-cu12==25.2.*->cuml-cu12) (1.17.0)\nLooking in indexes: https://pypi.org/simple, https://pypi.nvidia.com\nCollecting cugraph-cu12\n  Downloading https://pypi.nvidia.com/cugraph-cu12/cugraph_cu12-25.4.0-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (3.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: cuda-python<13.0a0,>=12.6.2 in /usr/local/lib/python3.11/dist-packages (from cugraph-cu12) (12.8.0)\nCollecting cudf-cu12==25.4.* (from cugraph-cu12)\n  Downloading https://pypi.nvidia.com/cudf-cu12/cudf_cu12-25.4.0-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (1.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m176.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: cupy-cuda12x>=12.0.0 in /usr/local/lib/python3.11/dist-packages (from cugraph-cu12) (13.4.1)\nCollecting dask-cuda==25.4.* (from cugraph-cu12)\n  Downloading https://pypi.nvidia.com/dask-cuda/dask_cuda-25.4.0-py3-none-any.whl (135 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.9/135.9 kB\u001b[0m \u001b[31m145.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting dask-cudf-cu12==25.4.* (from cugraph-cu12)\n  Downloading https://pypi.nvidia.com/dask-cudf-cu12/dask_cudf_cu12-25.4.0-py3-none-any.whl (50 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m90.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: fsspec>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=0.6.0->cugraph-cu12) (2025.3.2)\nCollecting libcugraph-cu12==25.4.* (from cugraph-cu12)\n  Downloading https://pypi.nvidia.com/libcugraph-cu12/libcugraph_cu12-25.4.0-py3-none-manylinux_2_28_x86_64.whl (1496.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 GB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: numba<0.61.0a0,>=0.59.1 in /usr/local/lib/python3.11/dist-packages (from cugraph-cu12) (0.60.0)\nRequirement already satisfied: numpy<3.0a0,>=1.23 in /usr/local/lib/python3.11/dist-packages (from cugraph-cu12) (1.26.4)\nCollecting pylibcugraph-cu12==25.4.* (from cugraph-cu12)\n  Downloading https://pypi.nvidia.com/pylibcugraph-cu12/pylibcugraph_cu12-25.4.0-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (2.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m168.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting pylibraft-cu12==25.4.* (from cugraph-cu12)\n  Downloading https://pypi.nvidia.com/pylibraft-cu12/pylibraft_cu12-25.4.0-cp311-cp311-manylinux_2_28_x86_64.whl (855 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m855.3/855.3 kB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting raft-dask-cu12==25.4.* (from cugraph-cu12)\n  Downloading https://pypi.nvidia.com/raft-dask-cu12/raft_dask_cu12-25.4.0-cp311-cp311-manylinux_2_28_x86_64.whl (288.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.3/288.3 MB\u001b[0m \u001b[31m69.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting rapids-dask-dependency==25.4.* (from cugraph-cu12)\n  Downloading https://pypi.nvidia.com/rapids-dask-dependency/rapids_dask_dependency-25.4.0-py3-none-any.whl (18 kB)\nCollecting rmm-cu12==25.4.* (from cugraph-cu12)\n  Downloading https://pypi.nvidia.com/rmm-cu12/rmm_cu12-25.4.0-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (1.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m170.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting ucx-py-cu12==0.43.* (from cugraph-cu12)\n  Downloading https://pypi.nvidia.com/ucx-py-cu12/ucx_py_cu12-0.43.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (2.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m158.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: cachetools in /usr/local/lib/python3.11/dist-packages (from cudf-cu12==25.4.*->cugraph-cu12) (5.5.2)\nCollecting libcudf-cu12==25.4.* (from cudf-cu12==25.4.*->cugraph-cu12)\n  Downloading https://pypi.nvidia.com/libcudf-cu12/libcudf_cu12-25.4.0-py3-none-manylinux_2_28_x86_64.whl (565.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m565.0/565.0 MB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting numba-cuda<0.5.0a0,>=0.4.0 (from cudf-cu12==25.4.*->cugraph-cu12)\n  Downloading numba_cuda-0.4.0-py3-none-any.whl.metadata (1.5 kB)\nRequirement already satisfied: nvtx>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from cudf-cu12==25.4.*->cugraph-cu12) (0.2.11)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from cudf-cu12==25.4.*->cugraph-cu12) (24.2)\nRequirement already satisfied: pandas<2.2.4dev0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from cudf-cu12==25.4.*->cugraph-cu12) (2.2.3)\nRequirement already satisfied: pyarrow<20.0.0a0,>=14.0.0 in /usr/local/lib/python3.11/dist-packages (from cudf-cu12==25.4.*->cugraph-cu12) (19.0.1)\nCollecting pylibcudf-cu12==25.4.* (from cudf-cu12==25.4.*->cugraph-cu12)\n  Downloading https://pypi.nvidia.com/pylibcudf-cu12/pylibcudf_cu12-25.4.0-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (27.7 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.7/27.7 MB\u001b[0m \u001b[31m98.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: pynvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from cudf-cu12==25.4.*->cugraph-cu12) (0.5.2)\nRequirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from cudf-cu12==25.4.*->cugraph-cu12) (14.0.0)\nRequirement already satisfied: typing_extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from cudf-cu12==25.4.*->cugraph-cu12) (4.13.1)\nRequirement already satisfied: click>=8.1 in /usr/local/lib/python3.11/dist-packages (from dask-cuda==25.4.*->cugraph-cu12) (8.1.8)\nRequirement already satisfied: pynvml<13.0.0a0,>=12.0.0 in /usr/local/lib/python3.11/dist-packages (from dask-cuda==25.4.*->cugraph-cu12) (12.0.0)\nRequirement already satisfied: zict>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from dask-cuda==25.4.*->cugraph-cu12) (3.0.0)\nCollecting libraft-cu12==25.4.* (from libcugraph-cu12==25.4.*->cugraph-cu12)\n  Downloading https://pypi.nvidia.com/libraft-cu12/libraft_cu12-25.4.0-py3-none-manylinux_2_28_x86_64.whl (21.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.8/21.8 MB\u001b[0m \u001b[31m154.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hCollecting distributed-ucxx-cu12==0.43.* (from raft-dask-cu12==25.4.*->cugraph-cu12)\n  Downloading https://pypi.nvidia.com/distributed-ucxx-cu12/distributed_ucxx_cu12-0.43.0-py3-none-any.whl (25 kB)\nCollecting dask==2025.2.0 (from rapids-dask-dependency==25.4.*->cugraph-cu12)\n  Downloading dask-2025.2.0-py3-none-any.whl.metadata (3.8 kB)\nCollecting distributed==2025.2.0 (from rapids-dask-dependency==25.4.*->cugraph-cu12)\n  Downloading distributed-2025.2.0-py3-none-any.whl.metadata (3.3 kB)\nCollecting librmm-cu12==25.4.* (from rmm-cu12==25.4.*->cugraph-cu12)\n  Downloading https://pypi.nvidia.com/librmm-cu12/librmm_cu12-25.4.0-py3-none-any.whl (3.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m194.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: libucx-cu12<1.19,>=1.15.0 in /usr/local/lib/python3.11/dist-packages (from ucx-py-cu12==0.43.*->cugraph-cu12) (1.18.0)\nRequirement already satisfied: cloudpickle>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from dask==2025.2.0->rapids-dask-dependency==25.4.*->cugraph-cu12) (3.1.1)\nRequirement already satisfied: partd>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from dask==2025.2.0->rapids-dask-dependency==25.4.*->cugraph-cu12) (1.4.2)\nRequirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from dask==2025.2.0->rapids-dask-dependency==25.4.*->cugraph-cu12) (6.0.2)\nRequirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from dask==2025.2.0->rapids-dask-dependency==25.4.*->cugraph-cu12) (1.0.0)\nRequirement already satisfied: importlib_metadata>=4.13.0 in /usr/local/lib/python3.11/dist-packages (from dask==2025.2.0->rapids-dask-dependency==25.4.*->cugraph-cu12) (8.6.1)\nRequirement already satisfied: jinja2>=2.10.3 in /usr/local/lib/python3.11/dist-packages (from distributed==2025.2.0->rapids-dask-dependency==25.4.*->cugraph-cu12) (3.1.6)\nRequirement already satisfied: locket>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from distributed==2025.2.0->rapids-dask-dependency==25.4.*->cugraph-cu12) (1.0.0)\nRequirement already satisfied: msgpack>=1.0.2 in /usr/local/lib/python3.11/dist-packages (from distributed==2025.2.0->rapids-dask-dependency==25.4.*->cugraph-cu12) (1.1.0)\nRequirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from distributed==2025.2.0->rapids-dask-dependency==25.4.*->cugraph-cu12) (7.0.0)\nRequirement already satisfied: sortedcontainers>=2.0.5 in /usr/local/lib/python3.11/dist-packages (from distributed==2025.2.0->rapids-dask-dependency==25.4.*->cugraph-cu12) (2.4.0)\nRequirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from distributed==2025.2.0->rapids-dask-dependency==25.4.*->cugraph-cu12) (3.1.0)\nRequirement already satisfied: tornado>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from distributed==2025.2.0->rapids-dask-dependency==25.4.*->cugraph-cu12) (6.4.2)\nRequirement already satisfied: urllib3>=1.26.5 in /usr/local/lib/python3.11/dist-packages (from distributed==2025.2.0->rapids-dask-dependency==25.4.*->cugraph-cu12) (2.3.0)\nCollecting ucxx-cu12==0.43.* (from distributed-ucxx-cu12==0.43.*->raft-dask-cu12==25.4.*->cugraph-cu12)\n  Downloading https://pypi.nvidia.com/ucxx-cu12/ucxx_cu12-0.43.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (725 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m725.9/725.9 kB\u001b[0m \u001b[31m186.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting libkvikio-cu12==25.4.* (from libcudf-cu12==25.4.*->cudf-cu12==25.4.*->cugraph-cu12)\n  Downloading https://pypi.nvidia.com/libkvikio-cu12/libkvikio_cu12-25.4.0-py3-none-manylinux_2_28_x86_64.whl (2.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m138.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: nvidia-nvcomp-cu12==4.2.0.11 in /usr/local/lib/python3.11/dist-packages (from libcudf-cu12==25.4.*->cudf-cu12==25.4.*->cugraph-cu12) (4.2.0.11)\nCollecting rapids-logger==0.1.* (from libcudf-cu12==25.4.*->cudf-cu12==25.4.*->cugraph-cu12)\n  Downloading rapids_logger-0.1.1-py3-none-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (3.5 kB)\nRequirement already satisfied: nvidia-cublas-cu12 in /usr/local/lib/python3.11/dist-packages (from libraft-cu12==25.4.*->libcugraph-cu12==25.4.*->cugraph-cu12) (12.8.4.1)\nRequirement already satisfied: nvidia-curand-cu12 in /usr/local/lib/python3.11/dist-packages (from libraft-cu12==25.4.*->libcugraph-cu12==25.4.*->cugraph-cu12) (10.3.9.90)\nRequirement already satisfied: nvidia-cusolver-cu12 in /usr/local/lib/python3.11/dist-packages (from libraft-cu12==25.4.*->libcugraph-cu12==25.4.*->cugraph-cu12) (11.7.3.90)\nRequirement already satisfied: nvidia-cusparse-cu12 in /usr/local/lib/python3.11/dist-packages (from libraft-cu12==25.4.*->libcugraph-cu12==25.4.*->cugraph-cu12) (12.5.8.93)\nCollecting libucxx-cu12==0.43.* (from ucxx-cu12==0.43.*->distributed-ucxx-cu12==0.43.*->raft-dask-cu12==25.4.*->cugraph-cu12)\n  Downloading https://pypi.nvidia.com/libucxx-cu12/libucxx_cu12-0.43.0-py3-none-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (515 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m515.3/515.3 kB\u001b[0m \u001b[31m195.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: cuda-bindings~=12.8.0 in /usr/local/lib/python3.11/dist-packages (from cuda-python<13.0a0,>=12.6.2->cugraph-cu12) (12.8.0)\nRequirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.11/dist-packages (from cupy-cuda12x>=12.0.0->cugraph-cu12) (0.8.3)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=0.6.0->cugraph-cu12) (3.11.16)\nRequirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba<0.61.0a0,>=0.59.1->cugraph-cu12) (0.43.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3.0a0,>=1.23->cugraph-cu12) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3.0a0,>=1.23->cugraph-cu12) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3.0a0,>=1.23->cugraph-cu12) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3.0a0,>=1.23->cugraph-cu12) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3.0a0,>=1.23->cugraph-cu12) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3.0a0,>=1.23->cugraph-cu12) (2.4.1)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=0.6.0->cugraph-cu12) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=0.6.0->cugraph-cu12) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=0.6.0->cugraph-cu12) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=0.6.0->cugraph-cu12) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=0.6.0->cugraph-cu12) (6.2.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=0.6.0->cugraph-cu12) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=0.6.0->cugraph-cu12) (1.19.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<2.2.4dev0,>=2.0->cudf-cu12==25.4.*->cugraph-cu12) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<2.2.4dev0,>=2.0->cudf-cu12==25.4.*->cugraph-cu12) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<2.2.4dev0,>=2.0->cudf-cu12==25.4.*->cugraph-cu12) (2025.2)\nRequirement already satisfied: nvidia-ml-py<13.0.0a0,>=12.0.0 in /usr/local/lib/python3.11/dist-packages (from pynvml<13.0.0a0,>=12.0.0->dask-cuda==25.4.*->cugraph-cu12) (12.570.86)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0a0,>=1.23->cugraph-cu12) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0a0,>=1.23->cugraph-cu12) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3.0a0,>=1.23->cugraph-cu12) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3.0a0,>=1.23->cugraph-cu12) (2024.2.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->cudf-cu12==25.4.*->cugraph-cu12) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->cudf-cu12==25.4.*->cugraph-cu12) (2.19.1)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata>=4.13.0->dask==2025.2.0->rapids-dask-dependency==25.4.*->cugraph-cu12) (3.21.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3.0a0,>=1.23->cugraph-cu12) (2024.2.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2>=2.10.3->distributed==2025.2.0->rapids-dask-dependency==25.4.*->cugraph-cu12) (3.0.2)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->cudf-cu12==25.4.*->cugraph-cu12) (0.1.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<2.2.4dev0,>=2.0->cudf-cu12==25.4.*->cugraph-cu12) (1.17.0)\nRequirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=0.6.0->cugraph-cu12) (3.10)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12->libraft-cu12==25.4.*->libcugraph-cu12==25.4.*->cugraph-cu12) (12.8.93)\nDownloading dask-2025.2.0-py3-none-any.whl (1.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading distributed-2025.2.0-py3-none-any.whl (1.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading rapids_logger-0.1.1-py3-none-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (192 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.0/193.0 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading numba_cuda-0.4.0-py3-none-any.whl (453 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m453.8/453.8 kB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: libkvikio-cu12, rapids-logger, librmm-cu12, dask, libucxx-cu12, libraft-cu12, libcudf-cu12, distributed, rapids-dask-dependency, libcugraph-cu12, rmm-cu12, ucxx-cu12, pylibcudf-cu12, numba-cuda, ucx-py-cu12, pylibraft-cu12, distributed-ucxx-cu12, dask-cuda, cudf-cu12, raft-dask-cu12, pylibcugraph-cu12, dask-cudf-cu12, cugraph-cu12\n  Attempting uninstall: libkvikio-cu12\n    Found existing installation: libkvikio-cu12 25.2.1\n    Uninstalling libkvikio-cu12-25.2.1:\n      Successfully uninstalled libkvikio-cu12-25.2.1\n  Attempting uninstall: dask\n    Found existing installation: dask 2024.12.1\n    Uninstalling dask-2024.12.1:\n      Successfully uninstalled dask-2024.12.1\n  Attempting uninstall: libucxx-cu12\n    Found existing installation: libucxx-cu12 0.42.0\n    Uninstalling libucxx-cu12-0.42.0:\n      Successfully uninstalled libucxx-cu12-0.42.0\n  Attempting uninstall: libraft-cu12\n    Found existing installation: libraft-cu12 25.2.0\n    Uninstalling libraft-cu12-25.2.0:\n      Successfully uninstalled libraft-cu12-25.2.0\n  Attempting uninstall: libcudf-cu12\n    Found existing installation: libcudf-cu12 25.2.2\n    Uninstalling libcudf-cu12-25.2.2:\n      Successfully uninstalled libcudf-cu12-25.2.2\n  Attempting uninstall: distributed\n    Found existing installation: distributed 2024.12.1\n    Uninstalling distributed-2024.12.1:\n      Successfully uninstalled distributed-2024.12.1\n  Attempting uninstall: rapids-dask-dependency\n    Found existing installation: rapids-dask-dependency 25.2.0\n    Uninstalling rapids-dask-dependency-25.2.0:\n      Successfully uninstalled rapids-dask-dependency-25.2.0\n  Attempting uninstall: rmm-cu12\n    Found existing installation: rmm-cu12 25.2.0\n    Uninstalling rmm-cu12-25.2.0:\n      Successfully uninstalled rmm-cu12-25.2.0\n  Attempting uninstall: ucxx-cu12\n    Found existing installation: ucxx-cu12 0.42.0\n    Uninstalling ucxx-cu12-0.42.0:\n      Successfully uninstalled ucxx-cu12-0.42.0\n  Attempting uninstall: pylibcudf-cu12\n    Found existing installation: pylibcudf-cu12 25.2.2\n    Uninstalling pylibcudf-cu12-25.2.2:\n      Successfully uninstalled pylibcudf-cu12-25.2.2\n  Attempting uninstall: numba-cuda\n    Found existing installation: numba-cuda 0.2.0\n    Uninstalling numba-cuda-0.2.0:\n      Successfully uninstalled numba-cuda-0.2.0\n  Attempting uninstall: ucx-py-cu12\n    Found existing installation: ucx-py-cu12 0.42.0\n    Uninstalling ucx-py-cu12-0.42.0:\n      Successfully uninstalled ucx-py-cu12-0.42.0\n  Attempting uninstall: pylibraft-cu12\n    Found existing installation: pylibraft-cu12 25.2.0\n    Uninstalling pylibraft-cu12-25.2.0:\n      Successfully uninstalled pylibraft-cu12-25.2.0\n  Attempting uninstall: distributed-ucxx-cu12\n    Found existing installation: distributed-ucxx-cu12 0.42.0\n    Uninstalling distributed-ucxx-cu12-0.42.0:\n      Successfully uninstalled distributed-ucxx-cu12-0.42.0\n  Attempting uninstall: dask-cuda\n    Found existing installation: dask-cuda 25.2.0\n    Uninstalling dask-cuda-25.2.0:\n      Successfully uninstalled dask-cuda-25.2.0\n  Attempting uninstall: cudf-cu12\n    Found existing installation: cudf-cu12 25.2.2\n    Uninstalling cudf-cu12-25.2.2:\n      Successfully uninstalled cudf-cu12-25.2.2\n  Attempting uninstall: raft-dask-cu12\n    Found existing installation: raft-dask-cu12 25.2.0\n    Uninstalling raft-dask-cu12-25.2.0:\n      Successfully uninstalled raft-dask-cu12-25.2.0\n  Attempting uninstall: pylibcugraph-cu12\n    Found existing installation: pylibcugraph-cu12 24.12.0\n    Uninstalling pylibcugraph-cu12-24.12.0:\n      Successfully uninstalled pylibcugraph-cu12-24.12.0\n  Attempting uninstall: dask-cudf-cu12\n    Found existing installation: dask-cudf-cu12 25.2.2\n    Uninstalling dask-cudf-cu12-25.2.2:\n      Successfully uninstalled dask-cudf-cu12-25.2.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nlibcuml-cu12 25.2.1 requires libraft-cu12==25.2.*, but you have libraft-cu12 25.4.0 which is incompatible.\nlibcuvs-cu12 25.2.1 requires libraft-cu12==25.2.*, but you have libraft-cu12 25.4.0 which is incompatible.\ndask-expr 1.1.21 requires dask==2024.12.1, but you have dask 2025.2.0 which is incompatible.\ncuml-cu12 25.2.1 requires cudf-cu12==25.2.*, but you have cudf-cu12 25.4.0 which is incompatible.\ncuml-cu12 25.2.1 requires dask-cuda==25.2.*, but you have dask-cuda 25.4.0 which is incompatible.\ncuml-cu12 25.2.1 requires dask-cudf-cu12==25.2.*, but you have dask-cudf-cu12 25.4.0 which is incompatible.\ncuml-cu12 25.2.1 requires pylibraft-cu12==25.2.*, but you have pylibraft-cu12 25.4.0 which is incompatible.\ncuml-cu12 25.2.1 requires raft-dask-cu12==25.2.*, but you have raft-dask-cu12 25.4.0 which is incompatible.\ncuml-cu12 25.2.1 requires rapids-dask-dependency==25.2.*, but you have rapids-dask-dependency 25.4.0 which is incompatible.\ncuml-cu12 25.2.1 requires rmm-cu12==25.2.*, but you have rmm-cu12 25.4.0 which is incompatible.\ncuvs-cu12 25.2.1 requires pylibraft-cu12==25.2.*, but you have pylibraft-cu12 25.4.0 which is incompatible.\nnx-cugraph-cu12 24.12.0 requires pylibcugraph-cu12==24.12.*, but you have pylibcugraph-cu12 25.4.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed cudf-cu12-25.4.0 cugraph-cu12-25.4.0 dask-2025.2.0 dask-cuda-25.4.0 dask-cudf-cu12-25.4.0 distributed-2025.2.0 distributed-ucxx-cu12-0.43.0 libcudf-cu12-25.4.0 libcugraph-cu12-25.4.0 libkvikio-cu12-25.4.0 libraft-cu12-25.4.0 librmm-cu12-25.4.0 libucxx-cu12-0.43.0 numba-cuda-0.4.0 pylibcudf-cu12-25.4.0 pylibcugraph-cu12-25.4.0 pylibraft-cu12-25.4.0 raft-dask-cu12-25.4.0 rapids-dask-dependency-25.4.0 rapids-logger-0.1.1 rmm-cu12-25.4.0 ucx-py-cu12-0.43.0 ucxx-cu12-0.43.0\nLooking in links: https://pip.cupy.dev/aarch64\nRequirement already satisfied: cupy-cuda12x in /usr/local/lib/python3.11/dist-packages (13.4.1)\nRequirement already satisfied: numpy<2.3,>=1.22 in /usr/local/lib/python3.11/dist-packages (from cupy-cuda12x) (1.26.4)\nRequirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.11/dist-packages (from cupy-cuda12x) (0.8.3)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<2.3,>=1.22->cupy-cuda12x) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<2.3,>=1.22->cupy-cuda12x) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<2.3,>=1.22->cupy-cuda12x) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<2.3,>=1.22->cupy-cuda12x) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<2.3,>=1.22->cupy-cuda12x) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<2.3,>=1.22->cupy-cuda12x) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.3,>=1.22->cupy-cuda12x) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.3,>=1.22->cupy-cuda12x) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<2.3,>=1.22->cupy-cuda12x) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<2.3,>=1.22->cupy-cuda12x) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<2.3,>=1.22->cupy-cuda12x) (2024.2.0)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/agriculture-data/cleaned_text_data.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T04:21:10.009970Z","iopub.execute_input":"2025-04-23T04:21:10.010220Z","iopub.status.idle":"2025-04-23T04:21:11.839155Z","shell.execute_reply.started":"2025-04-23T04:21:10.010199Z","shell.execute_reply":"2025-04-23T04:21:11.838573Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"data.head(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T18:35:00.997609Z","iopub.execute_input":"2025-04-22T18:35:00.997819Z","iopub.status.idle":"2025-04-22T18:35:01.019935Z","shell.execute_reply.started":"2025-04-22T18:35:00.997802Z","shell.execute_reply":"2025-04-22T18:35:01.019417Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                                text        date file_name\n0  With a big drop in Annual Investment Allowance...  2020-10-27   20.json\n1  Though the moisture was welcomed in much of th...  2020-10-27   61.json\n2  Hello and welcome to the ZimmCast. This podcas...  2020-10-27   36.json\n3  Ecological monitoring is the recording of biol...  2020-10-27   41.json\n4  Farmers have been encouraged to develop a cont...  2020-10-27   16.json\n5  Farming 18 blocks of land spread over the loca...  2020-10-27   57.json\n6  Published: Just now DecResearch Inc. is one of...  2020-10-27    6.json\n7  Global Modified Starch for Animal Feed Market ...  2020-10-27    7.json\n8  Sometimes, I sit down to write these columns w...  2020-10-27   56.json\n9  The Suckler Beef Climate Group has published i...  2020-10-27   17.json","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>date</th>\n      <th>file_name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>With a big drop in Annual Investment Allowance...</td>\n      <td>2020-10-27</td>\n      <td>20.json</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Though the moisture was welcomed in much of th...</td>\n      <td>2020-10-27</td>\n      <td>61.json</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Hello and welcome to the ZimmCast. This podcas...</td>\n      <td>2020-10-27</td>\n      <td>36.json</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Ecological monitoring is the recording of biol...</td>\n      <td>2020-10-27</td>\n      <td>41.json</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Farmers have been encouraged to develop a cont...</td>\n      <td>2020-10-27</td>\n      <td>16.json</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Farming 18 blocks of land spread over the loca...</td>\n      <td>2020-10-27</td>\n      <td>57.json</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Published: Just now DecResearch Inc. is one of...</td>\n      <td>2020-10-27</td>\n      <td>6.json</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Global Modified Starch for Animal Feed Market ...</td>\n      <td>2020-10-27</td>\n      <td>7.json</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Sometimes, I sit down to write these columns w...</td>\n      <td>2020-10-27</td>\n      <td>56.json</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>The Suckler Beef Climate Group has published i...</td>\n      <td>2020-10-27</td>\n      <td>17.json</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"# import nltk\n# nltk.download('punkt')\n\n# from nltk.tokenize import word_tokenize\n# data['token_count'] = data['text'].apply(lambda x: len(word_tokenize(x)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T15:52:27.770079Z","iopub.execute_input":"2025-04-22T15:52:27.770345Z","iopub.status.idle":"2025-04-22T15:52:27.780230Z","shell.execute_reply.started":"2025-04-22T15:52:27.770322Z","shell.execute_reply":"2025-04-22T15:52:27.779443Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"data.head(5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T15:52:27.780902Z","iopub.execute_input":"2025-04-22T15:52:27.781090Z","iopub.status.idle":"2025-04-22T15:52:27.800185Z","shell.execute_reply.started":"2025-04-22T15:52:27.781074Z","shell.execute_reply":"2025-04-22T15:52:27.799406Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                                                text        date file_name\n0  With a big drop in Annual Investment Allowance...  2020-10-27   20.json\n1  Though the moisture was welcomed in much of th...  2020-10-27   61.json\n2  Hello and welcome to the ZimmCast. This podcas...  2020-10-27   36.json\n3  Ecological monitoring is the recording of biol...  2020-10-27   41.json\n4  Farmers have been encouraged to develop a cont...  2020-10-27   16.json","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>date</th>\n      <th>file_name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>With a big drop in Annual Investment Allowance...</td>\n      <td>2020-10-27</td>\n      <td>20.json</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Though the moisture was welcomed in much of th...</td>\n      <td>2020-10-27</td>\n      <td>61.json</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Hello and welcome to the ZimmCast. This podcas...</td>\n      <td>2020-10-27</td>\n      <td>36.json</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Ecological monitoring is the recording of biol...</td>\n      <td>2020-10-27</td>\n      <td>41.json</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Farmers have been encouraged to develop a cont...</td>\n      <td>2020-10-27</td>\n      <td>16.json</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"data.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T04:21:11.839940Z","iopub.execute_input":"2025-04-23T04:21:11.840196Z","iopub.status.idle":"2025-04-23T04:21:11.846511Z","shell.execute_reply.started":"2025-04-23T04:21:11.840170Z","shell.execute_reply":"2025-04-23T04:21:11.845803Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"(22814, 3)"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"from typing import List\nimport re","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T04:21:11.848090Z","iopub.execute_input":"2025-04-23T04:21:11.848723Z","iopub.status.idle":"2025-04-23T04:21:11.855900Z","shell.execute_reply.started":"2025-04-23T04:21:11.848698Z","shell.execute_reply":"2025-04-23T04:21:11.855264Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def chunk_document(text: str, chunk_size: int = 100) -> List[str]:\n    try:\n        # Basic sentence splitting using common sentence endings\n        sentences = re.split(r'(?<=[.!?])\\s+', text)\n        \n        chunks = []\n        current_chunk = []\n        current_size = 0\n        \n        for sentence in sentences:\n            words = sentence.split()\n            if current_size + len(words) <= chunk_size:\n                current_chunk.append(sentence)\n                current_size += len(words)\n            else:\n                if current_chunk:\n                    chunks.append(' '.join(current_chunk))\n                current_chunk = [sentence]\n                current_size = len(words)\n        \n        if current_chunk:\n            chunks.append(' '.join(current_chunk))\n        \n        return chunks\n    except Exception as e:\n        print(f\"Error chunking document: {e}\")\n        return [text]  # Return original text if chunking fails","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T04:21:11.856554Z","iopub.execute_input":"2025-04-23T04:21:11.856754Z","iopub.status.idle":"2025-04-23T04:21:11.867166Z","shell.execute_reply.started":"2025-04-23T04:21:11.856729Z","shell.execute_reply":"2025-04-23T04:21:11.866662Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"data = data[['text']]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T04:21:11.867943Z","iopub.execute_input":"2025-04-23T04:21:11.868175Z","iopub.status.idle":"2025-04-23T04:21:11.892194Z","shell.execute_reply.started":"2025-04-23T04:21:11.868159Z","shell.execute_reply":"2025-04-23T04:21:11.891657Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"data.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T04:21:11.892806Z","iopub.execute_input":"2025-04-23T04:21:11.893080Z","iopub.status.idle":"2025-04-23T04:21:11.903564Z","shell.execute_reply.started":"2025-04-23T04:21:11.893059Z","shell.execute_reply":"2025-04-23T04:21:11.902900Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"(22814, 1)"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"chunked_data = []\n\nfor idx, row in data.iterrows():\n    text = row['text']\n    chunks = chunk_document(text, chunk_size=100)  # Adjust chunk_size as needed\n    \n    for chunk in chunks:\n        chunked_data.append({'original_index': idx, 'chunk': chunk})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T04:21:11.904170Z","iopub.execute_input":"2025-04-23T04:21:11.904377Z","iopub.status.idle":"2025-04-23T04:21:15.603446Z","shell.execute_reply.started":"2025-04-23T04:21:11.904364Z","shell.execute_reply":"2025-04-23T04:21:15.602876Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"chunked_df = pd.DataFrame(chunked_data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T04:21:15.604200Z","iopub.execute_input":"2025-04-23T04:21:15.605012Z","iopub.status.idle":"2025-04-23T04:21:15.721902Z","shell.execute_reply.started":"2025-04-23T04:21:15.604974Z","shell.execute_reply":"2025-04-23T04:21:15.721391Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"print(\"Shape of chunked DataFrame:\", chunked_df.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T04:21:15.724148Z","iopub.execute_input":"2025-04-23T04:21:15.724410Z","iopub.status.idle":"2025-04-23T04:21:15.728115Z","shell.execute_reply.started":"2025-04-23T04:21:15.724393Z","shell.execute_reply":"2025-04-23T04:21:15.727543Z"}},"outputs":[{"name":"stdout","text":"Shape of chunked DataFrame: (165322, 2)\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"!pip install llama-cpp-python --q\n!pip install bertopic --q","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T04:21:15.728763Z","iopub.execute_input":"2025-04-23T04:21:15.729039Z","iopub.status.idle":"2025-04-23T04:24:16.634003Z","shell.execute_reply.started":"2025-04-23T04:21:15.729016Z","shell.execute_reply":"2025-04-23T04:24:16.633086Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.6/150.6 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m61.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.8/88.8 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nlibcuml-cu12 25.2.1 requires libraft-cu12==25.2.*, but you have libraft-cu12 25.4.0 which is incompatible.\nlibcuvs-cu12 25.2.1 requires libraft-cu12==25.2.*, but you have libraft-cu12 25.4.0 which is incompatible.\ncuml-cu12 25.2.1 requires cudf-cu12==25.2.*, but you have cudf-cu12 25.4.0 which is incompatible.\ncuml-cu12 25.2.1 requires dask-cuda==25.2.*, but you have dask-cuda 25.4.0 which is incompatible.\ncuml-cu12 25.2.1 requires dask-cudf-cu12==25.2.*, but you have dask-cudf-cu12 25.4.0 which is incompatible.\ncuml-cu12 25.2.1 requires pylibraft-cu12==25.2.*, but you have pylibraft-cu12 25.4.0 which is incompatible.\ncuml-cu12 25.2.1 requires raft-dask-cu12==25.2.*, but you have raft-dask-cu12 25.4.0 which is incompatible.\ncuml-cu12 25.2.1 requires rapids-dask-dependency==25.2.*, but you have rapids-dask-dependency 25.4.0 which is incompatible.\ncuml-cu12 25.2.1 requires rmm-cu12==25.2.*, but you have rmm-cu12 25.4.0 which is incompatible.\ncuvs-cu12 25.2.1 requires pylibraft-cu12==25.2.*, but you have pylibraft-cu12 25.4.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"!wget https://huggingface.co/TheBloke/OpenHermes-2.5-Mistral-7B-GGUF/resolve/main/openhermes-2.5-mistral-7b.Q4_K_M.gguf\n# !wget https://huggingface.co/TheBloke/dolphin-2.7-mixtral-8x7b-GGUF/resolve/main/dolphin-2.7-mixtral-8x7b.Q3_K_M.gguf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T04:24:16.635121Z","iopub.execute_input":"2025-04-23T04:24:16.635417Z","iopub.status.idle":"2025-04-23T04:24:41.022690Z","shell.execute_reply.started":"2025-04-23T04:24:16.635384Z","shell.execute_reply":"2025-04-23T04:24:41.021708Z"}},"outputs":[{"name":"stdout","text":"--2025-04-23 04:24:16--  https://huggingface.co/TheBloke/OpenHermes-2.5-Mistral-7B-GGUF/resolve/main/openhermes-2.5-mistral-7b.Q4_K_M.gguf\nResolving huggingface.co (huggingface.co)... 18.238.136.32, 18.238.136.129, 18.238.136.112, ...\nConnecting to huggingface.co (huggingface.co)|18.238.136.32|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://cdn-lfs-us-1.hf.co/repos/65/3b/653b1cc7a4558cd22c0ac02df471105878a080cb5694622ccd566697c574592f/cd58120326971c71c0590f6b7084a0744e287ce9c67275d8b4bf34a5947d950b?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27openhermes-2.5-mistral-7b.Q4_K_M.gguf%3B+filename%3D%22openhermes-2.5-mistral-7b.Q4_K_M.gguf%22%3B&Expires=1745385856&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0NTM4NTg1Nn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzY1LzNiLzY1M2IxY2M3YTQ1NThjZDIyYzBhYzAyZGY0NzExMDU4NzhhMDgwY2I1Njk0NjIyY2NkNTY2Njk3YzU3NDU5MmYvY2Q1ODEyMDMyNjk3MWM3MWMwNTkwZjZiNzA4NGEwNzQ0ZTI4N2NlOWM2NzI3NWQ4YjRiZjM0YTU5NDdkOTUwYj9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=gHofX9e-ondUWK-Ie9F1L9k1ire-IqZiiSte1xTbwjEBGLLGvjQcmrfFBnPsX6wSzgsZhIsMhWmXFGWUy34W0YZp2xtcy7DkAH0RTP0iORqYW6%7E4netyQICpCYfvcZ3T2gc5oUqEr7U8udXPi2V5uRUpoeREhn0a2QmgrKEm9ZZ0O5CPCjxLeK2ZTfWzsEkdbGoEIS8yK74w7tSO6%7EKkmk7%7EEuyGpGbqO2eZAhVUQymjPUsIGP1qZHe-0353ARF5lC8fs0oxIQAWBr30ftkgcNn9pw6cm7IJzdeqp3QG8-oqkowppRb002IYZCN1H5tKbYSbQl3K42gzbmyQfkWjVg__&Key-Pair-Id=K24J24Z295AEI9 [following]\n--2025-04-23 04:24:16--  https://cdn-lfs-us-1.hf.co/repos/65/3b/653b1cc7a4558cd22c0ac02df471105878a080cb5694622ccd566697c574592f/cd58120326971c71c0590f6b7084a0744e287ce9c67275d8b4bf34a5947d950b?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27openhermes-2.5-mistral-7b.Q4_K_M.gguf%3B+filename%3D%22openhermes-2.5-mistral-7b.Q4_K_M.gguf%22%3B&Expires=1745385856&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0NTM4NTg1Nn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzY1LzNiLzY1M2IxY2M3YTQ1NThjZDIyYzBhYzAyZGY0NzExMDU4NzhhMDgwY2I1Njk0NjIyY2NkNTY2Njk3YzU3NDU5MmYvY2Q1ODEyMDMyNjk3MWM3MWMwNTkwZjZiNzA4NGEwNzQ0ZTI4N2NlOWM2NzI3NWQ4YjRiZjM0YTU5NDdkOTUwYj9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=gHofX9e-ondUWK-Ie9F1L9k1ire-IqZiiSte1xTbwjEBGLLGvjQcmrfFBnPsX6wSzgsZhIsMhWmXFGWUy34W0YZp2xtcy7DkAH0RTP0iORqYW6%7E4netyQICpCYfvcZ3T2gc5oUqEr7U8udXPi2V5uRUpoeREhn0a2QmgrKEm9ZZ0O5CPCjxLeK2ZTfWzsEkdbGoEIS8yK74w7tSO6%7EKkmk7%7EEuyGpGbqO2eZAhVUQymjPUsIGP1qZHe-0353ARF5lC8fs0oxIQAWBr30ftkgcNn9pw6cm7IJzdeqp3QG8-oqkowppRb002IYZCN1H5tKbYSbQl3K42gzbmyQfkWjVg__&Key-Pair-Id=K24J24Z295AEI9\nResolving cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)... 3.169.202.26, 3.169.202.105, 3.169.202.35, ...\nConnecting to cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)|3.169.202.26|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 4368450304 (4.1G) [binary/octet-stream]\nSaving to: ‘openhermes-2.5-mistral-7b.Q4_K_M.gguf.2’\n\nopenhermes-2.5-mist 100%[===================>]   4.07G   180MB/s    in 24s     \n\n2025-04-23 04:24:40 (174 MB/s) - ‘openhermes-2.5-mistral-7b.Q4_K_M.gguf.2’ saved [4368450304/4368450304]\n\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"from llama_cpp import Llama\nllm = Llama(model_path=\"openhermes-2.5-mistral-7b.Q4_K_M.gguf\", n_gpu_layers=-1, n_ctx=4096, stop=[\"Q:\", \"\\n\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T04:24:41.023897Z","iopub.execute_input":"2025-04-23T04:24:41.024185Z","iopub.status.idle":"2025-04-23T04:24:56.215581Z","shell.execute_reply.started":"2025-04-23T04:24:41.024150Z","shell.execute_reply":"2025-04-23T04:24:56.214141Z"}},"outputs":[{"name":"stderr","text":"llama_model_loader: loaded meta data with 20 key-value pairs and 291 tensors from openhermes-2.5-mistral-7b.Q4_K_M.gguf (version GGUF V3 (latest))\nllama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\nllama_model_loader: - kv   0:                       general.architecture str              = llama\nllama_model_loader: - kv   1:                               general.name str              = teknium_openhermes-2.5-mistral-7b\nllama_model_loader: - kv   2:                       llama.context_length u32              = 32768\nllama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\nllama_model_loader: - kv   4:                          llama.block_count u32              = 32\nllama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\nllama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\nllama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\nllama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\nllama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\nllama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 10000.000000\nllama_model_loader: - kv  11:                          general.file_type u32              = 15\nllama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\nllama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32002]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\nllama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32002]   = [0.000000, 0.000000, 0.000000, 0.0000...\nllama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32002]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\nllama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\nllama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 32000\nllama_model_loader: - kv  18:            tokenizer.ggml.padding_token_id u32              = 0\nllama_model_loader: - kv  19:               general.quantization_version u32              = 2\nllama_model_loader: - type  f32:   65 tensors\nllama_model_loader: - type q4_K:  193 tensors\nllama_model_loader: - type q6_K:   33 tensors\nprint_info: file format = GGUF V3 (latest)\nprint_info: file type   = Q4_K - Medium\nprint_info: file size   = 4.07 GiB (4.83 BPW) \ninit_tokenizer: initializing tokenizer for type 1\nload: control-looking token:  32000 '<|im_end|>' was not control-type; this is probably a bug in the model. its type will be overridden\nload: control token:      2 '</s>' is not marked as EOG\nload: control token:      1 '<s>' is not marked as EOG\nload: special tokens cache size = 5\nload: token to piece cache size = 0.1637 MB\nprint_info: arch             = llama\nprint_info: vocab_only       = 0\nprint_info: n_ctx_train      = 32768\nprint_info: n_embd           = 4096\nprint_info: n_layer          = 32\nprint_info: n_head           = 32\nprint_info: n_head_kv        = 8\nprint_info: n_rot            = 128\nprint_info: n_swa            = 0\nprint_info: n_embd_head_k    = 128\nprint_info: n_embd_head_v    = 128\nprint_info: n_gqa            = 4\nprint_info: n_embd_k_gqa     = 1024\nprint_info: n_embd_v_gqa     = 1024\nprint_info: f_norm_eps       = 0.0e+00\nprint_info: f_norm_rms_eps   = 1.0e-05\nprint_info: f_clamp_kqv      = 0.0e+00\nprint_info: f_max_alibi_bias = 0.0e+00\nprint_info: f_logit_scale    = 0.0e+00\nprint_info: f_attn_scale     = 0.0e+00\nprint_info: n_ff             = 14336\nprint_info: n_expert         = 0\nprint_info: n_expert_used    = 0\nprint_info: causal attn      = 1\nprint_info: pooling type     = 0\nprint_info: rope type        = 0\nprint_info: rope scaling     = linear\nprint_info: freq_base_train  = 10000.0\nprint_info: freq_scale_train = 1\nprint_info: n_ctx_orig_yarn  = 32768\nprint_info: rope_finetuned   = unknown\nprint_info: ssm_d_conv       = 0\nprint_info: ssm_d_inner      = 0\nprint_info: ssm_d_state      = 0\nprint_info: ssm_dt_rank      = 0\nprint_info: ssm_dt_b_c_rms   = 0\nprint_info: model type       = 7B\nprint_info: model params     = 7.24 B\nprint_info: general.name     = teknium_openhermes-2.5-mistral-7b\nprint_info: vocab type       = SPM\nprint_info: n_vocab          = 32002\nprint_info: n_merges         = 0\nprint_info: BOS token        = 1 '<s>'\nprint_info: EOS token        = 32000 '<|im_end|>'\nprint_info: EOT token        = 32000 '<|im_end|>'\nprint_info: UNK token        = 0 '<unk>'\nprint_info: PAD token        = 0 '<unk>'\nprint_info: LF token         = 13 '<0x0A>'\nprint_info: EOG token        = 32000 '<|im_end|>'\nprint_info: max token length = 48\nload_tensors: loading model tensors, this can take a while... (mmap = true)\nload_tensors: layer   0 assigned to device CPU\nload_tensors: layer   1 assigned to device CPU\nload_tensors: layer   2 assigned to device CPU\nload_tensors: layer   3 assigned to device CPU\nload_tensors: layer   4 assigned to device CPU\nload_tensors: layer   5 assigned to device CPU\nload_tensors: layer   6 assigned to device CPU\nload_tensors: layer   7 assigned to device CPU\nload_tensors: layer   8 assigned to device CPU\nload_tensors: layer   9 assigned to device CPU\nload_tensors: layer  10 assigned to device CPU\nload_tensors: layer  11 assigned to device CPU\nload_tensors: layer  12 assigned to device CPU\nload_tensors: layer  13 assigned to device CPU\nload_tensors: layer  14 assigned to device CPU\nload_tensors: layer  15 assigned to device CPU\nload_tensors: layer  16 assigned to device CPU\nload_tensors: layer  17 assigned to device CPU\nload_tensors: layer  18 assigned to device CPU\nload_tensors: layer  19 assigned to device CPU\nload_tensors: layer  20 assigned to device CPU\nload_tensors: layer  21 assigned to device CPU\nload_tensors: layer  22 assigned to device CPU\nload_tensors: layer  23 assigned to device CPU\nload_tensors: layer  24 assigned to device CPU\nload_tensors: layer  25 assigned to device CPU\nload_tensors: layer  26 assigned to device CPU\nload_tensors: layer  27 assigned to device CPU\nload_tensors: layer  28 assigned to device CPU\nload_tensors: layer  29 assigned to device CPU\nload_tensors: layer  30 assigned to device CPU\nload_tensors: layer  31 assigned to device CPU\nload_tensors: layer  32 assigned to device CPU\nload_tensors: tensor 'token_embd.weight' (q4_K) (and 290 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead\nload_tensors:   CPU_Mapped model buffer size =  4165.38 MiB\n.................................................................................................\nllama_init_from_model: n_seq_max     = 1\nllama_init_from_model: n_ctx         = 4096\nllama_init_from_model: n_ctx_per_seq = 4096\nllama_init_from_model: n_batch       = 512\nllama_init_from_model: n_ubatch      = 512\nllama_init_from_model: flash_attn    = 0\nllama_init_from_model: freq_base     = 10000.0\nllama_init_from_model: freq_scale    = 1\nllama_init_from_model: n_ctx_per_seq (4096) < n_ctx_train (32768) -- the full capacity of the model will not be utilized\nllama_kv_cache_init: kv_size = 4096, offload = 1, type_k = 'f16', type_v = 'f16', n_layer = 32, can_shift = 1\nllama_kv_cache_init: layer 0: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\nllama_kv_cache_init: layer 1: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\nllama_kv_cache_init: layer 2: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\nllama_kv_cache_init: layer 3: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\nllama_kv_cache_init: layer 4: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\nllama_kv_cache_init: layer 5: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\nllama_kv_cache_init: layer 6: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\nllama_kv_cache_init: layer 7: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\nllama_kv_cache_init: layer 8: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\nllama_kv_cache_init: layer 9: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\nllama_kv_cache_init: layer 10: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\nllama_kv_cache_init: layer 11: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\nllama_kv_cache_init: layer 12: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\nllama_kv_cache_init: layer 13: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\nllama_kv_cache_init: layer 14: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\nllama_kv_cache_init: layer 15: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\nllama_kv_cache_init: layer 16: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\nllama_kv_cache_init: layer 17: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\nllama_kv_cache_init: layer 18: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\nllama_kv_cache_init: layer 19: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\nllama_kv_cache_init: layer 20: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\nllama_kv_cache_init: layer 21: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\nllama_kv_cache_init: layer 22: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\nllama_kv_cache_init: layer 23: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\nllama_kv_cache_init: layer 24: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\nllama_kv_cache_init: layer 25: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\nllama_kv_cache_init: layer 26: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\nllama_kv_cache_init: layer 27: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\nllama_kv_cache_init: layer 28: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\nllama_kv_cache_init: layer 29: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\nllama_kv_cache_init: layer 30: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\nllama_kv_cache_init: layer 31: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\nllama_kv_cache_init:        CPU KV buffer size =   512.00 MiB\nllama_init_from_model: KV self size  =  512.00 MiB, K (f16):  256.00 MiB, V (f16):  256.00 MiB\nllama_init_from_model:        CPU  output buffer size =     0.12 MiB\nllama_init_from_model:        CPU compute buffer size =   296.01 MiB\nllama_init_from_model: graph nodes  = 1030\nllama_init_from_model: graph splits = 1\nCPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | BMI2 = 1 | AVX512 = 1 | LLAMAFILE = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | \nModel metadata: {'tokenizer.ggml.padding_token_id': '0', 'tokenizer.ggml.eos_token_id': '32000', 'general.architecture': 'llama', 'llama.rope.freq_base': '10000.000000', 'llama.context_length': '32768', 'general.name': 'teknium_openhermes-2.5-mistral-7b', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '14336', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.dimension_count': '128', 'tokenizer.ggml.bos_token_id': '1', 'llama.attention.head_count': '32', 'llama.block_count': '32', 'llama.attention.head_count_kv': '8', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '15'}\nUsing fallback chat format: llama-2\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"from bertopic.representation import LlamaCPP\n\nprompt = \"\"\" Q:\nI have a topic that contains the following documents:\n[DOCUMENTS]\n\nThe topic is described by the following keywords: '[KEYWORDS]'.\n\nBased on the above information, can you give a short label of the topic of at most 5 words?\nA:\n\"\"\"\n\nrepresentation_model = {\n    \"LLM\": LlamaCPP(llm, prompt=prompt)\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T04:24:56.216395Z","iopub.execute_input":"2025-04-23T04:24:56.216796Z","iopub.status.idle":"2025-04-23T04:25:46.553049Z","shell.execute_reply.started":"2025-04-23T04:24:56.216776Z","shell.execute_reply":"2025-04-23T04:25:46.552507Z"}},"outputs":[{"name":"stderr","text":"2025-04-23 04:25:15.664538: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1745382315.853862      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1745382315.907398      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"docs= chunked_df['chunk']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T04:25:46.553721Z","iopub.execute_input":"2025-04-23T04:25:46.554280Z","iopub.status.idle":"2025-04-23T04:25:46.558326Z","shell.execute_reply.started":"2025-04-23T04:25:46.554259Z","shell.execute_reply":"2025-04-23T04:25:46.557580Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"len(docs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T04:25:46.559132Z","iopub.execute_input":"2025-04-23T04:25:46.559395Z","iopub.status.idle":"2025-04-23T04:25:46.820113Z","shell.execute_reply.started":"2025-04-23T04:25:46.559373Z","shell.execute_reply":"2025-04-23T04:25:46.819505Z"}},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"165322"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer\nfrom cuml.manifold import UMAP\nfrom cuml.cluster import HDBSCAN\n# from umap import UMAP\n# from hdbscan import HDBSCAN\n\n# Pre-calculate embeddings\nembedding_model = SentenceTransformer(\"BAAI/bge-small-en\")\nembeddings = embedding_model.encode(docs, show_progress_bar=True)\n\n# Pre-reduce embeddings for visualization purposes\nreduced_embeddings = UMAP(n_neighbors=15, n_components=2, min_dist=0.0, metric='cosine', random_state=42).fit_transform(embeddings)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T04:25:46.822041Z","iopub.execute_input":"2025-04-23T04:25:46.822292Z","iopub.status.idle":"2025-04-23T04:33:12.844107Z","shell.execute_reply.started":"2025-04-23T04:25:46.822274Z","shell.execute_reply":"2025-04-23T04:33:12.843528Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"78c50d0f2a44498dba6db5e7adb60175"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c3d12908bee4129910af598a39272db"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/90.8k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b45c84f64862443697782bf0ba8faedb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc373f801e2d4e708d1da5eab2e28ae2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/684 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1d79c99e46ea4df19628216975aa448b"}},"metadata":{}},{"name":"stderr","text":"Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/133M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"12277948349b46f0a9e6c884e7468d55"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/366 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b634cf974c554319906601b26aa13b4a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c536f56e24743cbb7b4310a3b398215"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a511def518c4d589cb17b4ac7e96d00"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"602b5449b87b4008a8cc9c648468793a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6fe2b4c5e16438784120d0cf1e7fb41"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/5167 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9642b585d0504503ba59d04defe99253"}},"metadata":{}},{"name":"stdout","text":"[2025-04-23 04:33:02.778] [CUML] [info] build_algo set to brute_force_knn because random_state is given\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T04:33:12.844857Z","iopub.execute_input":"2025-04-23T04:33:12.845112Z","iopub.status.idle":"2025-04-23T04:33:12.849011Z","shell.execute_reply.started":"2025-04-23T04:33:12.845090Z","shell.execute_reply":"2025-04-23T04:33:12.848415Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"# Define sub-models\n# umap_model = UMAP(n_neighbors=15, n_components=5, min_dist=0.0, metric='cosine', random_state=42)\numap_model = UMAP(n_neighbors=10, n_components=3, min_dist=0.1, metric='cosine', random_state=42, low_memory=True)\n# hdbscan_model = HDBSCAN(min_cluster_size=150, metric='euclidean', cluster_selection_method='eom', prediction_data=True)\nhdbscan_model = HDBSCAN(min_cluster_size=100, min_samples=5, metric='euclidean', cluster_selection_method='eom', prediction_data=True)\nvectorizer_model = CountVectorizer(stop_words=\"english\", ngram_range=(2, 2))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T04:33:12.849816Z","iopub.execute_input":"2025-04-23T04:33:12.850079Z","iopub.status.idle":"2025-04-23T04:33:12.864804Z","shell.execute_reply.started":"2025-04-23T04:33:12.850056Z","shell.execute_reply":"2025-04-23T04:33:12.864185Z"}},"outputs":[{"name":"stdout","text":"[2025-04-23 04:33:12.860] [CUML] [info] Unused keyword parameter: low_memory during cuML estimator initialization\n[2025-04-23 04:33:12.861] [CUML] [info] build_algo set to brute_force_knn because random_state is given\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"from bertopic import BERTopic\n\ntopic_model = BERTopic(\n\n  # Sub-models\n  embedding_model=embedding_model,\n  umap_model=umap_model,\n  hdbscan_model=hdbscan_model,vectorizer_model = vectorizer_model,\n  representation_model=representation_model,\n\n  # Hyperparameters\n  top_n_words=10,\n  verbose=True\n)\n\n# Train model\ntopics, probs = topic_model.fit_transform(docs, embeddings)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T04:39:42.714333Z","iopub.execute_input":"2025-04-23T04:39:42.715018Z","iopub.status.idle":"2025-04-23T12:25:27.530860Z","shell.execute_reply.started":"2025-04-23T04:39:42.714992Z","shell.execute_reply":"2025-04-23T12:25:27.530273Z"}},"outputs":[{"name":"stderr","text":"2025-04-23 04:39:42,782 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n2025-04-23 04:40:01,149 - BERTopic - Dimensionality - Completed ✓\n2025-04-23 04:40:01,160 - BERTopic - Cluster - Start clustering the reduced embeddings\n2025-04-23 04:40:09,700 - BERTopic - Cluster - Completed ✓\n2025-04-23 04:40:09,736 - BERTopic - Representation - Fine-tuning topics using representation models.\n  0%|          | 0/183 [00:00<?, ?it/s]llama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  146423.54 ms /   808 tokens (  181.22 ms per token,     5.52 tokens per second)\nllama_perf_context_print:        eval time =    1975.28 ms /     6 runs   (  329.21 ms per token,     3.04 tokens per second)\nllama_perf_context_print:       total time =  148402.73 ms /   814 tokens\n  1%|          | 1/183 [02:28<7:30:10, 148.41s/it]Llama.generate: 43 prefix-match hit, remaining 935 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  171851.91 ms /   935 tokens (  183.80 ms per token,     5.44 tokens per second)\nllama_perf_context_print:        eval time =    5367.59 ms /    14 runs   (  383.40 ms per token,     2.61 tokens per second)\nllama_perf_context_print:       total time =  177227.39 ms /   949 tokens\n  1%|          | 2/183 [05:25<8:18:51, 165.37s/it]Llama.generate: 43 prefix-match hit, remaining 1308 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  241987.33 ms /  1308 tokens (  185.01 ms per token,     5.41 tokens per second)\nllama_perf_context_print:        eval time =    1721.25 ms /     5 runs   (  344.25 ms per token,     2.90 tokens per second)\nllama_perf_context_print:       total time =  243712.02 ms /  1313 tokens\n  2%|▏         | 3/183 [09:29<10:03:25, 201.14s/it]Llama.generate: 43 prefix-match hit, remaining 535 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =   96658.71 ms /   535 tokens (  180.67 ms per token,     5.53 tokens per second)\nllama_perf_context_print:        eval time =    2276.00 ms /     7 runs   (  325.14 ms per token,     3.08 tokens per second)\nllama_perf_context_print:       total time =   98938.97 ms /   542 tokens\n  2%|▏         | 4/183 [11:08<7:59:42, 160.80s/it] Llama.generate: 43 prefix-match hit, remaining 746 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  134999.64 ms /   746 tokens (  180.96 ms per token,     5.53 tokens per second)\nllama_perf_context_print:        eval time =    3575.85 ms /    10 runs   (  357.58 ms per token,     2.80 tokens per second)\nllama_perf_context_print:       total time =  138582.00 ms /   756 tokens\n  3%|▎         | 5/183 [13:26<7:33:16, 152.79s/it]Llama.generate: 43 prefix-match hit, remaining 776 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  140346.38 ms /   776 tokens (  180.86 ms per token,     5.53 tokens per second)\nllama_perf_context_print:        eval time =    2654.69 ms /     8 runs   (  331.84 ms per token,     3.01 tokens per second)\nllama_perf_context_print:       total time =  143006.16 ms /   784 tokens\n  3%|▎         | 6/183 [15:49<7:20:55, 149.47s/it]Llama.generate: 43 prefix-match hit, remaining 859 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  156562.61 ms /   859 tokens (  182.26 ms per token,     5.49 tokens per second)\nllama_perf_context_print:        eval time =    3332.81 ms /    10 runs   (  333.28 ms per token,     3.00 tokens per second)\nllama_perf_context_print:       total time =  159901.10 ms /   869 tokens\n  4%|▍         | 7/183 [18:29<7:28:26, 152.88s/it]Llama.generate: 43 prefix-match hit, remaining 766 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  138760.26 ms /   766 tokens (  181.15 ms per token,     5.52 tokens per second)\nllama_perf_context_print:        eval time =    2299.43 ms /     7 runs   (  328.49 ms per token,     3.04 tokens per second)\nllama_perf_context_print:       total time =  141064.00 ms /   773 tokens\n  4%|▍         | 8/183 [20:50<7:14:56, 149.12s/it]Llama.generate: 43 prefix-match hit, remaining 690 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  126645.70 ms /   690 tokens (  183.54 ms per token,     5.45 tokens per second)\nllama_perf_context_print:        eval time =    3612.06 ms /    11 runs   (  328.37 ms per token,     3.05 tokens per second)\nllama_perf_context_print:       total time =  130263.64 ms /   701 tokens\n  5%|▍         | 9/183 [23:01<6:55:21, 143.23s/it]Llama.generate: 43 prefix-match hit, remaining 967 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  178410.65 ms /   967 tokens (  184.50 ms per token,     5.42 tokens per second)\nllama_perf_context_print:        eval time =    6354.16 ms /    19 runs   (  334.43 ms per token,     2.99 tokens per second)\nllama_perf_context_print:       total time =  184774.50 ms /   986 tokens\n  5%|▌         | 10/183 [26:05<7:29:57, 156.06s/it]Llama.generate: 43 prefix-match hit, remaining 634 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  115450.19 ms /   634 tokens (  182.10 ms per token,     5.49 tokens per second)\nllama_perf_context_print:        eval time =    1978.27 ms /     6 runs   (  329.71 ms per token,     3.03 tokens per second)\nllama_perf_context_print:       total time =  117432.51 ms /   640 tokens\n  6%|▌         | 11/183 [28:03<6:53:28, 144.24s/it]Llama.generate: 43 prefix-match hit, remaining 595 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  108393.18 ms /   595 tokens (  182.17 ms per token,     5.49 tokens per second)\nllama_perf_context_print:        eval time =    2026.36 ms /     6 runs   (  337.73 ms per token,     2.96 tokens per second)\nllama_perf_context_print:       total time =  110423.56 ms /   601 tokens\n  7%|▋         | 12/183 [29:53<6:21:46, 133.95s/it]Llama.generate: 43 prefix-match hit, remaining 682 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  123390.92 ms /   682 tokens (  180.93 ms per token,     5.53 tokens per second)\nllama_perf_context_print:        eval time =    3337.90 ms /    10 runs   (  333.79 ms per token,     3.00 tokens per second)\nllama_perf_context_print:       total time =  126734.38 ms /   692 tokens\n  7%|▋         | 13/183 [32:00<6:13:20, 131.77s/it]Llama.generate: 43 prefix-match hit, remaining 700 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  126178.04 ms /   700 tokens (  180.25 ms per token,     5.55 tokens per second)\nllama_perf_context_print:        eval time =    2610.51 ms /     8 runs   (  326.31 ms per token,     3.06 tokens per second)\nllama_perf_context_print:       total time =  128793.04 ms /   708 tokens\n  8%|▊         | 14/183 [34:09<6:08:37, 130.87s/it]Llama.generate: 43 prefix-match hit, remaining 719 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  129630.54 ms /   719 tokens (  180.29 ms per token,     5.55 tokens per second)\nllama_perf_context_print:        eval time =   13152.35 ms /    39 runs   (  337.24 ms per token,     2.97 tokens per second)\nllama_perf_context_print:       total time =  142804.02 ms /   758 tokens\n  8%|▊         | 15/183 [36:32<6:16:31, 134.47s/it]Llama.generate: 43 prefix-match hit, remaining 632 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  113733.42 ms /   632 tokens (  179.96 ms per token,     5.56 tokens per second)\nllama_perf_context_print:        eval time =    1915.85 ms /     6 runs   (  319.31 ms per token,     3.13 tokens per second)\nllama_perf_context_print:       total time =  115652.96 ms /   638 tokens\n  9%|▊         | 16/183 [38:27<5:58:31, 128.81s/it]Llama.generate: 43 prefix-match hit, remaining 644 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  115809.65 ms /   644 tokens (  179.83 ms per token,     5.56 tokens per second)\nllama_perf_context_print:        eval time =    1973.75 ms /     6 runs   (  328.96 ms per token,     3.04 tokens per second)\nllama_perf_context_print:       total time =  117787.38 ms /   650 tokens\n  9%|▉         | 17/183 [40:25<5:47:12, 125.50s/it]Llama.generate: 43 prefix-match hit, remaining 625 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  111520.97 ms /   625 tokens (  178.43 ms per token,     5.60 tokens per second)\nllama_perf_context_print:        eval time =    3923.56 ms /    12 runs   (  326.96 ms per token,     3.06 tokens per second)\nllama_perf_context_print:       total time =  115451.23 ms /   637 tokens\n 10%|▉         | 18/183 [42:21<5:36:49, 122.48s/it]Llama.generate: 43 prefix-match hit, remaining 732 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  133384.27 ms /   732 tokens (  182.22 ms per token,     5.49 tokens per second)\nllama_perf_context_print:        eval time =    3622.59 ms /    11 runs   (  329.33 ms per token,     3.04 tokens per second)\nllama_perf_context_print:       total time =  137012.81 ms /   743 tokens\n 10%|█         | 19/183 [44:38<5:46:42, 126.85s/it]Llama.generate: 43 prefix-match hit, remaining 712 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  129530.76 ms /   712 tokens (  181.93 ms per token,     5.50 tokens per second)\nllama_perf_context_print:        eval time =    3625.67 ms /    11 runs   (  329.61 ms per token,     3.03 tokens per second)\nllama_perf_context_print:       total time =  133162.41 ms /   723 tokens\n 11%|█         | 20/183 [46:51<5:49:45, 128.75s/it]Llama.generate: 43 prefix-match hit, remaining 757 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  136493.15 ms /   757 tokens (  180.31 ms per token,     5.55 tokens per second)\nllama_perf_context_print:        eval time =    2291.94 ms /     7 runs   (  327.42 ms per token,     3.05 tokens per second)\nllama_perf_context_print:       total time =  138789.36 ms /   764 tokens\n 11%|█▏        | 21/183 [49:10<5:55:45, 131.76s/it]Llama.generate: 43 prefix-match hit, remaining 656 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  119222.15 ms /   656 tokens (  181.74 ms per token,     5.50 tokens per second)\nllama_perf_context_print:        eval time =    2920.22 ms /     9 runs   (  324.47 ms per token,     3.08 tokens per second)\nllama_perf_context_print:       total time =  122147.43 ms /   665 tokens\n 12%|█▏        | 22/183 [51:12<5:45:49, 128.88s/it]Llama.generate: 43 prefix-match hit, remaining 1688 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  310587.24 ms /  1688 tokens (  184.00 ms per token,     5.43 tokens per second)\nllama_perf_context_print:        eval time =    4555.76 ms /    13 runs   (  350.44 ms per token,     2.85 tokens per second)\nllama_perf_context_print:       total time =  315149.68 ms /  1701 tokens\n 13%|█▎        | 23/183 [56:27<8:12:44, 184.78s/it]Llama.generate: 43 prefix-match hit, remaining 781 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  142192.21 ms /   781 tokens (  182.06 ms per token,     5.49 tokens per second)\nllama_perf_context_print:        eval time =    2602.82 ms /     8 runs   (  325.35 ms per token,     3.07 tokens per second)\nllama_perf_context_print:       total time =  144799.94 ms /   789 tokens\n 13%|█▎        | 24/183 [58:52<7:37:52, 172.78s/it]Llama.generate: 43 prefix-match hit, remaining 741 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  137074.87 ms /   741 tokens (  184.99 ms per token,     5.41 tokens per second)\nllama_perf_context_print:        eval time =    3919.43 ms /    11 runs   (  356.31 ms per token,     2.81 tokens per second)\nllama_perf_context_print:       total time =  141000.18 ms /   752 tokens\n 14%|█▎        | 25/183 [1:01:13<7:09:53, 163.25s/it]Llama.generate: 43 prefix-match hit, remaining 702 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  130485.62 ms /   702 tokens (  185.88 ms per token,     5.38 tokens per second)\nllama_perf_context_print:        eval time =    2301.26 ms /     7 runs   (  328.75 ms per token,     3.04 tokens per second)\nllama_perf_context_print:       total time =  132791.22 ms /   709 tokens\n 14%|█▍        | 26/183 [1:03:26<6:43:15, 154.11s/it]Llama.generate: 43 prefix-match hit, remaining 551 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  101698.84 ms /   551 tokens (  184.57 ms per token,     5.42 tokens per second)\nllama_perf_context_print:        eval time =    4339.72 ms /    13 runs   (  333.82 ms per token,     3.00 tokens per second)\nllama_perf_context_print:       total time =  106045.59 ms /   564 tokens\n 15%|█▍        | 27/183 [1:05:12<6:03:12, 139.69s/it]Llama.generate: 43 prefix-match hit, remaining 670 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  125405.48 ms /   670 tokens (  187.17 ms per token,     5.34 tokens per second)\nllama_perf_context_print:        eval time =    3920.16 ms /    12 runs   (  326.68 ms per token,     3.06 tokens per second)\nllama_perf_context_print:       total time =  129332.03 ms /   682 tokens\n 15%|█▌        | 28/183 [1:07:21<5:52:51, 136.59s/it]Llama.generate: 43 prefix-match hit, remaining 597 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  108076.33 ms /   597 tokens (  181.03 ms per token,     5.52 tokens per second)\nllama_perf_context_print:        eval time =    2625.55 ms /     8 runs   (  328.19 ms per token,     3.05 tokens per second)\nllama_perf_context_print:       total time =  110706.37 ms /   605 tokens\n 16%|█▌        | 29/183 [1:09:12<5:30:39, 128.83s/it]Llama.generate: 43 prefix-match hit, remaining 678 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  123626.39 ms /   678 tokens (  182.34 ms per token,     5.48 tokens per second)\nllama_perf_context_print:        eval time =   12041.09 ms /    36 runs   (  334.47 ms per token,     2.99 tokens per second)\nllama_perf_context_print:       total time =  135685.13 ms /   714 tokens\n 16%|█▋        | 30/183 [1:11:27<5:33:45, 130.89s/it]Llama.generate: 43 prefix-match hit, remaining 657 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  118846.04 ms /   657 tokens (  180.89 ms per token,     5.53 tokens per second)\nllama_perf_context_print:        eval time =    1945.45 ms /     6 runs   (  324.24 ms per token,     3.08 tokens per second)\nllama_perf_context_print:       total time =  120795.42 ms /   663 tokens\n 17%|█▋        | 31/183 [1:13:28<5:23:54, 127.86s/it]Llama.generate: 43 prefix-match hit, remaining 963 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  177992.61 ms /   963 tokens (  184.83 ms per token,     5.41 tokens per second)\nllama_perf_context_print:        eval time =    2386.49 ms /     7 runs   (  340.93 ms per token,     2.93 tokens per second)\nllama_perf_context_print:       total time =  180383.37 ms /   970 tokens\n 17%|█▋        | 32/183 [1:16:28<6:01:26, 143.62s/it]Llama.generate: 44 prefix-match hit, remaining 686 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  124805.14 ms /   686 tokens (  181.93 ms per token,     5.50 tokens per second)\nllama_perf_context_print:        eval time =    2263.13 ms /     7 runs   (  323.30 ms per token,     3.09 tokens per second)\nllama_perf_context_print:       total time =  127072.44 ms /   693 tokens\n 18%|█▊        | 33/183 [1:18:36<5:46:38, 138.66s/it]Llama.generate: 43 prefix-match hit, remaining 650 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  117840.68 ms /   650 tokens (  181.29 ms per token,     5.52 tokens per second)\nllama_perf_context_print:        eval time =   10842.74 ms /    33 runs   (  328.57 ms per token,     3.04 tokens per second)\nllama_perf_context_print:       total time =  128699.10 ms /   683 tokens\n 19%|█▊        | 34/183 [1:20:44<5:36:55, 135.67s/it]Llama.generate: 43 prefix-match hit, remaining 3280 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  631416.29 ms /  3280 tokens (  192.50 ms per token,     5.19 tokens per second)\nllama_perf_context_print:        eval time =    2517.37 ms /     6 runs   (  419.56 ms per token,     2.38 tokens per second)\nllama_perf_context_print:       total time =  633937.48 ms /  3286 tokens\n 19%|█▉        | 35/183 [1:31:18<11:43:23, 285.16s/it]Llama.generate: 43 prefix-match hit, remaining 692 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  124271.42 ms /   692 tokens (  179.58 ms per token,     5.57 tokens per second)\nllama_perf_context_print:        eval time =    2634.82 ms /     8 runs   (  329.35 ms per token,     3.04 tokens per second)\nllama_perf_context_print:       total time =  126911.10 ms /   700 tokens\n 20%|█▉        | 36/183 [1:33:25<9:42:19, 237.68s/it] Llama.generate: 43 prefix-match hit, remaining 642 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  114673.26 ms /   642 tokens (  178.62 ms per token,     5.60 tokens per second)\nllama_perf_context_print:        eval time =    1936.47 ms /     6 runs   (  322.74 ms per token,     3.10 tokens per second)\nllama_perf_context_print:       total time =  116613.64 ms /   648 tokens\n 20%|██        | 37/183 [1:35:22<8:09:59, 201.37s/it]Llama.generate: 43 prefix-match hit, remaining 645 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  116065.36 ms /   645 tokens (  179.95 ms per token,     5.56 tokens per second)\nllama_perf_context_print:        eval time =    2557.30 ms /     8 runs   (  319.66 ms per token,     3.13 tokens per second)\nllama_perf_context_print:       total time =  118627.04 ms /   653 tokens\n 21%|██        | 38/183 [1:37:20<7:06:39, 176.55s/it]Llama.generate: 43 prefix-match hit, remaining 578 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  104202.57 ms /   578 tokens (  180.28 ms per token,     5.55 tokens per second)\nllama_perf_context_print:        eval time =    2570.10 ms /     8 runs   (  321.26 ms per token,     3.11 tokens per second)\nllama_perf_context_print:       total time =  106777.13 ms /   586 tokens\n 21%|██▏       | 39/183 [1:39:07<6:13:28, 155.62s/it]Llama.generate: 43 prefix-match hit, remaining 1051 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  190748.15 ms /  1051 tokens (  181.49 ms per token,     5.51 tokens per second)\nllama_perf_context_print:        eval time =    2666.11 ms /     8 runs   (  333.26 ms per token,     3.00 tokens per second)\nllama_perf_context_print:       total time =  193418.88 ms /  1059 tokens\n 22%|██▏       | 40/183 [1:42:21<6:37:55, 166.96s/it]Llama.generate: 43 prefix-match hit, remaining 692 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  125972.46 ms /   692 tokens (  182.04 ms per token,     5.49 tokens per second)\nllama_perf_context_print:        eval time =    3898.29 ms /    12 runs   (  324.86 ms per token,     3.08 tokens per second)\nllama_perf_context_print:       total time =  129877.06 ms /   704 tokens\n 22%|██▏       | 41/183 [1:44:31<6:08:48, 155.84s/it]Llama.generate: 43 prefix-match hit, remaining 701 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  127388.53 ms /   701 tokens (  181.72 ms per token,     5.50 tokens per second)\nllama_perf_context_print:        eval time =    4543.28 ms /    14 runs   (  324.52 ms per token,     3.08 tokens per second)\nllama_perf_context_print:       total time =  131939.00 ms /   715 tokens\n 23%|██▎       | 42/183 [1:46:42<5:49:22, 148.67s/it]Llama.generate: 43 prefix-match hit, remaining 404 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =   72510.62 ms /   404 tokens (  179.48 ms per token,     5.57 tokens per second)\nllama_perf_context_print:        eval time =    4130.02 ms /    12 runs   (  344.17 ms per token,     2.91 tokens per second)\nllama_perf_context_print:       total time =   76647.61 ms /   416 tokens\n 23%|██▎       | 43/183 [1:47:59<4:56:29, 127.07s/it]Llama.generate: 43 prefix-match hit, remaining 885 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  160484.80 ms /   885 tokens (  181.34 ms per token,     5.51 tokens per second)\nllama_perf_context_print:        eval time =    4219.51 ms /    13 runs   (  324.58 ms per token,     3.08 tokens per second)\nllama_perf_context_print:       total time =  164710.82 ms /   898 tokens\n 24%|██▍       | 44/183 [1:50:44<5:20:32, 138.36s/it]Llama.generate: 43 prefix-match hit, remaining 639 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  114938.43 ms /   639 tokens (  179.87 ms per token,     5.56 tokens per second)\nllama_perf_context_print:        eval time =    3861.32 ms /    12 runs   (  321.78 ms per token,     3.11 tokens per second)\nllama_perf_context_print:       total time =  118806.03 ms /   651 tokens\n 25%|██▍       | 45/183 [1:52:43<5:04:44, 132.50s/it]Llama.generate: 43 prefix-match hit, remaining 856 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  156577.41 ms /   856 tokens (  182.92 ms per token,     5.47 tokens per second)\nllama_perf_context_print:        eval time =    3306.07 ms /    10 runs   (  330.61 ms per token,     3.02 tokens per second)\nllama_perf_context_print:       total time =  159888.73 ms /   866 tokens\n 25%|██▌       | 46/183 [1:55:23<5:21:18, 140.72s/it]Llama.generate: 43 prefix-match hit, remaining 655 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  117816.84 ms /   655 tokens (  179.87 ms per token,     5.56 tokens per second)\nllama_perf_context_print:        eval time =    3218.18 ms /    10 runs   (  321.82 ms per token,     3.11 tokens per second)\nllama_perf_context_print:       total time =  121040.58 ms /   665 tokens\n 26%|██▌       | 47/183 [1:57:24<5:05:34, 134.82s/it]Llama.generate: 43 prefix-match hit, remaining 718 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  128192.01 ms /   718 tokens (  178.54 ms per token,     5.60 tokens per second)\nllama_perf_context_print:        eval time =    2290.93 ms /     7 runs   (  327.28 ms per token,     3.06 tokens per second)\nllama_perf_context_print:       total time =  130487.27 ms /   725 tokens\n 26%|██▌       | 48/183 [1:59:34<5:00:25, 133.52s/it]Llama.generate: 43 prefix-match hit, remaining 601 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  108867.07 ms /   601 tokens (  181.14 ms per token,     5.52 tokens per second)\nllama_perf_context_print:        eval time =    2955.50 ms /     9 runs   (  328.39 ms per token,     3.05 tokens per second)\nllama_perf_context_print:       total time =  111827.67 ms /   610 tokens\n 27%|██▋       | 49/183 [2:01:26<4:43:39, 127.01s/it]Llama.generate: 43 prefix-match hit, remaining 648 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  115881.26 ms /   648 tokens (  178.83 ms per token,     5.59 tokens per second)\nllama_perf_context_print:        eval time =    1640.60 ms /     5 runs   (  328.12 ms per token,     3.05 tokens per second)\nllama_perf_context_print:       total time =  117525.29 ms /   653 tokens\n 27%|██▋       | 50/183 [2:03:23<4:35:14, 124.17s/it]Llama.generate: 43 prefix-match hit, remaining 667 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  120994.10 ms /   667 tokens (  181.40 ms per token,     5.51 tokens per second)\nllama_perf_context_print:        eval time =    1985.19 ms /     6 runs   (  330.87 ms per token,     3.02 tokens per second)\nllama_perf_context_print:       total time =  122983.07 ms /   673 tokens\n 28%|██▊       | 51/183 [2:05:26<4:32:23, 123.82s/it]Llama.generate: 43 prefix-match hit, remaining 1217 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  222642.26 ms /  1217 tokens (  182.94 ms per token,     5.47 tokens per second)\nllama_perf_context_print:        eval time =    2989.42 ms /     9 runs   (  332.16 ms per token,     3.01 tokens per second)\nllama_perf_context_print:       total time =  225636.56 ms /  1226 tokens\n 28%|██▊       | 52/183 [2:09:12<5:37:01, 154.36s/it]Llama.generate: 43 prefix-match hit, remaining 684 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  122369.24 ms /   684 tokens (  178.90 ms per token,     5.59 tokens per second)\nllama_perf_context_print:        eval time =    1949.78 ms /     6 runs   (  324.96 ms per token,     3.08 tokens per second)\nllama_perf_context_print:       total time =  124323.08 ms /   690 tokens\n 29%|██▉       | 53/183 [2:11:16<5:14:55, 145.35s/it]Llama.generate: 43 prefix-match hit, remaining 637 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  113598.73 ms /   637 tokens (  178.33 ms per token,     5.61 tokens per second)\nllama_perf_context_print:        eval time =    5436.03 ms /    16 runs   (  339.75 ms per token,     2.94 tokens per second)\nllama_perf_context_print:       total time =  119043.41 ms /   653 tokens\n 30%|██▉       | 54/183 [2:13:15<4:55:32, 137.46s/it]Llama.generate: 43 prefix-match hit, remaining 843 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  152255.88 ms /   843 tokens (  180.61 ms per token,     5.54 tokens per second)\nllama_perf_context_print:        eval time =    1958.11 ms /     6 runs   (  326.35 ms per token,     3.06 tokens per second)\nllama_perf_context_print:       total time =  154217.63 ms /   849 tokens\n 30%|███       | 55/183 [2:15:50<5:03:58, 142.49s/it]Llama.generate: 43 prefix-match hit, remaining 637 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  116676.20 ms /   637 tokens (  183.17 ms per token,     5.46 tokens per second)\nllama_perf_context_print:        eval time =    2624.84 ms /     8 runs   (  328.11 ms per token,     3.05 tokens per second)\nllama_perf_context_print:       total time =  119305.81 ms /   645 tokens\n 31%|███       | 56/183 [2:17:49<4:46:53, 135.54s/it]Llama.generate: 43 prefix-match hit, remaining 986 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  182975.40 ms /   986 tokens (  185.57 ms per token,     5.39 tokens per second)\nllama_perf_context_print:        eval time =    3031.51 ms /     9 runs   (  336.83 ms per token,     2.97 tokens per second)\nllama_perf_context_print:       total time =  186011.98 ms /   995 tokens\n 31%|███       | 57/183 [2:20:55<5:16:25, 150.68s/it]Llama.generate: 43 prefix-match hit, remaining 793 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  142158.96 ms /   793 tokens (  179.27 ms per token,     5.58 tokens per second)\nllama_perf_context_print:        eval time =    3267.03 ms /    10 runs   (  326.70 ms per token,     3.06 tokens per second)\nllama_perf_context_print:       total time =  145431.47 ms /   803 tokens\n 32%|███▏      | 58/183 [2:23:20<5:10:38, 149.11s/it]Llama.generate: 43 prefix-match hit, remaining 601 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  108349.01 ms /   601 tokens (  180.28 ms per token,     5.55 tokens per second)\nllama_perf_context_print:        eval time =    2889.42 ms /     9 runs   (  321.05 ms per token,     3.11 tokens per second)\nllama_perf_context_print:       total time =  111243.38 ms /   610 tokens\n 32%|███▏      | 59/183 [2:25:12<4:44:41, 137.75s/it]Llama.generate: 43 prefix-match hit, remaining 706 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  127573.91 ms /   706 tokens (  180.70 ms per token,     5.53 tokens per second)\nllama_perf_context_print:        eval time =    2893.94 ms /     9 runs   (  321.55 ms per token,     3.11 tokens per second)\nllama_perf_context_print:       total time =  130472.80 ms /   715 tokens\n 33%|███▎      | 60/183 [2:27:22<4:37:55, 135.57s/it]Llama.generate: 43 prefix-match hit, remaining 732 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  132866.10 ms /   732 tokens (  181.51 ms per token,     5.51 tokens per second)\nllama_perf_context_print:        eval time =    2625.96 ms /     8 runs   (  328.25 ms per token,     3.05 tokens per second)\nllama_perf_context_print:       total time =  135496.84 ms /   740 tokens\n 33%|███▎      | 61/183 [2:29:38<4:35:37, 135.55s/it]Llama.generate: 43 prefix-match hit, remaining 691 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  124350.11 ms /   691 tokens (  179.96 ms per token,     5.56 tokens per second)\nllama_perf_context_print:        eval time =    1945.35 ms /     6 runs   (  324.22 ms per token,     3.08 tokens per second)\nllama_perf_context_print:       total time =  126299.15 ms /   697 tokens\n 34%|███▍      | 62/183 [2:31:44<4:27:46, 132.78s/it]Llama.generate: 43 prefix-match hit, remaining 634 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  114618.91 ms /   634 tokens (  180.79 ms per token,     5.53 tokens per second)\nllama_perf_context_print:        eval time =    2551.82 ms /     8 runs   (  318.98 ms per token,     3.14 tokens per second)\nllama_perf_context_print:       total time =  117175.19 ms /   642 tokens\n 34%|███▍      | 63/183 [2:33:41<4:16:11, 128.10s/it]Llama.generate: 43 prefix-match hit, remaining 626 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  113079.36 ms /   626 tokens (  180.64 ms per token,     5.54 tokens per second)\nllama_perf_context_print:        eval time =    2881.82 ms /     9 runs   (  320.20 ms per token,     3.12 tokens per second)\nllama_perf_context_print:       total time =  115966.09 ms /   635 tokens\n 35%|███▍      | 64/183 [2:35:37<4:06:50, 124.46s/it]Llama.generate: 43 prefix-match hit, remaining 774 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  141098.76 ms /   774 tokens (  182.30 ms per token,     5.49 tokens per second)\nllama_perf_context_print:        eval time =    2279.16 ms /     7 runs   (  325.59 ms per token,     3.07 tokens per second)\nllama_perf_context_print:       total time =  143382.11 ms /   781 tokens\n 36%|███▌      | 65/183 [2:38:01<4:15:56, 130.14s/it]Llama.generate: 43 prefix-match hit, remaining 682 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  124364.86 ms /   682 tokens (  182.35 ms per token,     5.48 tokens per second)\nllama_perf_context_print:        eval time =    3887.17 ms /    12 runs   (  323.93 ms per token,     3.09 tokens per second)\nllama_perf_context_print:       total time =  128258.21 ms /   694 tokens\n 36%|███▌      | 66/183 [2:40:09<4:12:40, 129.58s/it]Llama.generate: 43 prefix-match hit, remaining 704 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  127069.72 ms /   704 tokens (  180.50 ms per token,     5.54 tokens per second)\nllama_perf_context_print:        eval time =    3847.21 ms /    12 runs   (  320.60 ms per token,     3.12 tokens per second)\nllama_perf_context_print:       total time =  130923.37 ms /   716 tokens\n 37%|███▋      | 67/183 [2:42:20<4:11:18, 129.98s/it]Llama.generate: 43 prefix-match hit, remaining 634 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  113937.12 ms /   634 tokens (  179.71 ms per token,     5.56 tokens per second)\nllama_perf_context_print:        eval time =    3884.24 ms /    12 runs   (  323.69 ms per token,     3.09 tokens per second)\nllama_perf_context_print:       total time =  117827.78 ms /   646 tokens\n 37%|███▋      | 68/183 [2:44:18<4:02:08, 126.34s/it]Llama.generate: 43 prefix-match hit, remaining 796 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  144094.73 ms /   796 tokens (  181.02 ms per token,     5.52 tokens per second)\nllama_perf_context_print:        eval time =    3270.16 ms /    10 runs   (  327.02 ms per token,     3.06 tokens per second)\nllama_perf_context_print:       total time =  147370.14 ms /   806 tokens\n 38%|███▊      | 69/183 [2:46:45<4:12:02, 132.65s/it]Llama.generate: 43 prefix-match hit, remaining 550 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =   99616.96 ms /   550 tokens (  181.12 ms per token,     5.52 tokens per second)\nllama_perf_context_print:        eval time =    1937.04 ms /     6 runs   (  322.84 ms per token,     3.10 tokens per second)\nllama_perf_context_print:       total time =  101557.93 ms /   556 tokens\n 38%|███▊      | 70/183 [2:48:27<3:52:15, 123.32s/it]Llama.generate: 43 prefix-match hit, remaining 582 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  104100.37 ms /   582 tokens (  178.87 ms per token,     5.59 tokens per second)\nllama_perf_context_print:        eval time =    3814.11 ms /    11 runs   (  346.74 ms per token,     2.88 tokens per second)\nllama_perf_context_print:       total time =  107920.34 ms /   593 tokens\n 39%|███▉      | 71/183 [2:50:14<3:41:35, 118.71s/it]Llama.generate: 43 prefix-match hit, remaining 769 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  139408.80 ms /   769 tokens (  181.29 ms per token,     5.52 tokens per second)\nllama_perf_context_print:        eval time =    2892.86 ms /     9 runs   (  321.43 ms per token,     3.11 tokens per second)\nllama_perf_context_print:       total time =  142306.71 ms /   778 tokens\n 39%|███▉      | 72/183 [2:52:37<3:52:42, 125.79s/it]Llama.generate: 43 prefix-match hit, remaining 504 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =   90678.19 ms /   504 tokens (  179.92 ms per token,     5.56 tokens per second)\nllama_perf_context_print:        eval time =    2251.91 ms /     7 runs   (  321.70 ms per token,     3.11 tokens per second)\nllama_perf_context_print:       total time =   92934.51 ms /   511 tokens\n 40%|███▉      | 73/183 [2:54:10<3:32:32, 115.93s/it]Llama.generate: 43 prefix-match hit, remaining 303 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =   54182.05 ms /   303 tokens (  178.82 ms per token,     5.59 tokens per second)\nllama_perf_context_print:        eval time =    2459.86 ms /     7 runs   (  351.41 ms per token,     2.85 tokens per second)\nllama_perf_context_print:       total time =   56646.00 ms /   310 tokens\n 40%|████      | 74/183 [2:55:06<2:58:18, 98.15s/it] Llama.generate: 43 prefix-match hit, remaining 642 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  116162.21 ms /   642 tokens (  180.94 ms per token,     5.53 tokens per second)\nllama_perf_context_print:        eval time =    1943.12 ms /     6 runs   (  323.85 ms per token,     3.09 tokens per second)\nllama_perf_context_print:       total time =  118109.09 ms /   648 tokens\n 41%|████      | 75/183 [2:57:04<3:07:27, 104.14s/it]Llama.generate: 43 prefix-match hit, remaining 541 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =   97372.86 ms /   541 tokens (  179.99 ms per token,     5.56 tokens per second)\nllama_perf_context_print:        eval time =    3545.46 ms /    11 runs   (  322.31 ms per token,     3.10 tokens per second)\nllama_perf_context_print:       total time =  100924.37 ms /   552 tokens\n 42%|████▏     | 76/183 [2:58:45<3:03:59, 103.18s/it]Llama.generate: 43 prefix-match hit, remaining 729 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  133462.89 ms /   729 tokens (  183.08 ms per token,     5.46 tokens per second)\nllama_perf_context_print:        eval time =    1621.14 ms /     5 runs   (  324.23 ms per token,     3.08 tokens per second)\nllama_perf_context_print:       total time =  135087.36 ms /   734 tokens\n 42%|████▏     | 77/183 [3:01:00<3:19:11, 112.75s/it]Llama.generate: 44 prefix-match hit, remaining 684 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  122820.87 ms /   684 tokens (  179.56 ms per token,     5.57 tokens per second)\nllama_perf_context_print:        eval time =    2383.91 ms /     7 runs   (  340.56 ms per token,     2.94 tokens per second)\nllama_perf_context_print:       total time =  125209.03 ms /   691 tokens\n 43%|████▎     | 78/183 [3:03:06<3:23:51, 116.49s/it]Llama.generate: 43 prefix-match hit, remaining 687 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  125112.76 ms /   687 tokens (  182.11 ms per token,     5.49 tokens per second)\nllama_perf_context_print:        eval time =    1996.50 ms /     6 runs   (  332.75 ms per token,     3.01 tokens per second)\nllama_perf_context_print:       total time =  127113.27 ms /   693 tokens\n 43%|████▎     | 79/183 [3:05:13<3:27:26, 119.68s/it]Llama.generate: 43 prefix-match hit, remaining 715 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  130470.63 ms /   715 tokens (  182.48 ms per token,     5.48 tokens per second)\nllama_perf_context_print:        eval time =    2477.54 ms /     7 runs   (  353.93 ms per token,     2.83 tokens per second)\nllama_perf_context_print:       total time =  132952.95 ms /   722 tokens\n 44%|████▎     | 80/183 [3:07:26<3:32:17, 123.66s/it]Llama.generate: 43 prefix-match hit, remaining 584 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  104831.82 ms /   584 tokens (  179.51 ms per token,     5.57 tokens per second)\nllama_perf_context_print:        eval time =    2920.13 ms /     9 runs   (  324.46 ms per token,     3.08 tokens per second)\nllama_perf_context_print:       total time =  107756.98 ms /   593 tokens\n 44%|████▍     | 81/183 [3:09:14<3:22:07, 118.89s/it]Llama.generate: 43 prefix-match hit, remaining 683 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  123580.54 ms /   683 tokens (  180.94 ms per token,     5.53 tokens per second)\nllama_perf_context_print:        eval time =    2286.46 ms /     7 runs   (  326.64 ms per token,     3.06 tokens per second)\nllama_perf_context_print:       total time =  125871.34 ms /   690 tokens\n 45%|████▍     | 82/183 [3:11:19<3:23:39, 120.99s/it]Llama.generate: 43 prefix-match hit, remaining 1344 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  246152.05 ms /  1344 tokens (  183.15 ms per token,     5.46 tokens per second)\nllama_perf_context_print:        eval time =    3311.97 ms /     9 runs   (  368.00 ms per token,     2.72 tokens per second)\nllama_perf_context_print:       total time =  249468.97 ms /  1353 tokens\n 45%|████▌     | 83/183 [3:15:29<4:25:53, 159.54s/it]Llama.generate: 43 prefix-match hit, remaining 660 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  118634.53 ms /   660 tokens (  179.75 ms per token,     5.56 tokens per second)\nllama_perf_context_print:        eval time =    1617.18 ms /     5 runs   (  323.44 ms per token,     3.09 tokens per second)\nllama_perf_context_print:       total time =  120255.08 ms /   665 tokens\n 46%|████▌     | 84/183 [3:17:29<4:03:47, 147.75s/it]Llama.generate: 43 prefix-match hit, remaining 787 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  142841.94 ms /   787 tokens (  181.50 ms per token,     5.51 tokens per second)\nllama_perf_context_print:        eval time =    5686.41 ms /    17 runs   (  334.49 ms per token,     2.99 tokens per second)\nllama_perf_context_print:       total time =  148536.71 ms /   804 tokens\n 46%|████▋     | 85/183 [3:19:58<4:01:43, 147.99s/it]Llama.generate: 43 prefix-match hit, remaining 977 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  177117.03 ms /   977 tokens (  181.29 ms per token,     5.52 tokens per second)\nllama_perf_context_print:        eval time =    8925.65 ms /    26 runs   (  343.29 ms per token,     2.91 tokens per second)\nllama_perf_context_print:       total time =  186055.70 ms /  1003 tokens\n 47%|████▋     | 86/183 [3:23:04<4:17:43, 159.41s/it]Llama.generate: 43 prefix-match hit, remaining 680 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  124528.89 ms /   680 tokens (  183.13 ms per token,     5.46 tokens per second)\nllama_perf_context_print:        eval time =    7274.07 ms /    22 runs   (  330.64 ms per token,     3.02 tokens per second)\nllama_perf_context_print:       total time =  131813.83 ms /   702 tokens\n 48%|████▊     | 87/183 [3:25:16<4:01:48, 151.14s/it]Llama.generate: 43 prefix-match hit, remaining 604 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  110720.64 ms /   604 tokens (  183.31 ms per token,     5.46 tokens per second)\nllama_perf_context_print:        eval time =    3892.02 ms /    12 runs   (  324.33 ms per token,     3.08 tokens per second)\nllama_perf_context_print:       total time =  114618.98 ms /   616 tokens\n 48%|████▊     | 88/183 [3:27:10<3:41:57, 140.18s/it]Llama.generate: 43 prefix-match hit, remaining 596 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  109016.72 ms /   596 tokens (  182.91 ms per token,     5.47 tokens per second)\nllama_perf_context_print:        eval time =    2594.85 ms /     8 runs   (  324.36 ms per token,     3.08 tokens per second)\nllama_perf_context_print:       total time =  111616.08 ms /   604 tokens\n 49%|████▊     | 89/183 [3:29:02<3:26:11, 131.61s/it]Llama.generate: 43 prefix-match hit, remaining 644 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  116136.28 ms /   644 tokens (  180.34 ms per token,     5.55 tokens per second)\nllama_perf_context_print:        eval time =    3822.78 ms /    11 runs   (  347.53 ms per token,     2.88 tokens per second)\nllama_perf_context_print:       total time =  119965.04 ms /   655 tokens\n 49%|████▉     | 90/183 [3:31:02<3:18:35, 128.12s/it]Llama.generate: 43 prefix-match hit, remaining 680 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  122738.27 ms /   680 tokens (  180.50 ms per token,     5.54 tokens per second)\nllama_perf_context_print:        eval time =    2327.70 ms /     7 runs   (  332.53 ms per token,     3.01 tokens per second)\nllama_perf_context_print:       total time =  125070.30 ms /   687 tokens\n 50%|████▉     | 91/183 [3:33:07<3:15:03, 127.21s/it]Llama.generate: 43 prefix-match hit, remaining 748 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  135575.95 ms /   748 tokens (  181.25 ms per token,     5.52 tokens per second)\nllama_perf_context_print:        eval time =    6909.20 ms /    21 runs   (  329.01 ms per token,     3.04 tokens per second)\nllama_perf_context_print:       total time =  142495.55 ms /   769 tokens\n 50%|█████     | 92/183 [3:35:29<3:19:53, 131.80s/it]Llama.generate: 43 prefix-match hit, remaining 696 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  124672.95 ms /   696 tokens (  179.13 ms per token,     5.58 tokens per second)\nllama_perf_context_print:        eval time =    2542.91 ms /     8 runs   (  317.86 ms per token,     3.15 tokens per second)\nllama_perf_context_print:       total time =  127220.25 ms /   704 tokens\n 51%|█████     | 93/183 [3:37:37<3:15:38, 130.43s/it]Llama.generate: 43 prefix-match hit, remaining 595 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  106748.88 ms /   595 tokens (  179.41 ms per token,     5.57 tokens per second)\nllama_perf_context_print:        eval time =    2225.49 ms /     7 runs   (  317.93 ms per token,     3.15 tokens per second)\nllama_perf_context_print:       total time =  108978.53 ms /   602 tokens\n 51%|█████▏    | 94/183 [3:39:26<3:03:55, 123.99s/it]Llama.generate: 43 prefix-match hit, remaining 2771 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  521425.18 ms /  2771 tokens (  188.17 ms per token,     5.31 tokens per second)\nllama_perf_context_print:        eval time =    8852.24 ms /    23 runs   (  384.88 ms per token,     2.60 tokens per second)\nllama_perf_context_print:       total time =  530288.74 ms /  2794 tokens\n 52%|█████▏    | 95/183 [3:48:16<6:00:37, 245.89s/it]Llama.generate: 43 prefix-match hit, remaining 631 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  112660.70 ms /   631 tokens (  178.54 ms per token,     5.60 tokens per second)\nllama_perf_context_print:        eval time =    3917.09 ms /    12 runs   (  326.42 ms per token,     3.06 tokens per second)\nllama_perf_context_print:       total time =  116584.40 ms /   643 tokens\n 52%|█████▏    | 96/183 [3:50:12<5:00:17, 207.10s/it]Llama.generate: 43 prefix-match hit, remaining 723 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  130272.29 ms /   723 tokens (  180.18 ms per token,     5.55 tokens per second)\nllama_perf_context_print:        eval time =    2277.04 ms /     7 runs   (  325.29 ms per token,     3.07 tokens per second)\nllama_perf_context_print:       total time =  132553.40 ms /   730 tokens\n 53%|█████▎    | 97/183 [3:52:25<4:24:47, 184.74s/it]Llama.generate: 43 prefix-match hit, remaining 446 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =   80353.28 ms /   446 tokens (  180.16 ms per token,     5.55 tokens per second)\nllama_perf_context_print:        eval time =    2865.11 ms /     9 runs   (  318.35 ms per token,     3.14 tokens per second)\nllama_perf_context_print:       total time =   83223.23 ms /   455 tokens\n 54%|█████▎    | 98/183 [3:53:48<3:38:34, 154.28s/it]Llama.generate: 43 prefix-match hit, remaining 626 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  113967.51 ms /   626 tokens (  182.06 ms per token,     5.49 tokens per second)\nllama_perf_context_print:        eval time =    2291.24 ms /     7 runs   (  327.32 ms per token,     3.06 tokens per second)\nllama_perf_context_print:       total time =  116262.93 ms /   633 tokens\n 54%|█████▍    | 99/183 [3:55:45<3:20:01, 142.88s/it]Llama.generate: 43 prefix-match hit, remaining 697 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  127381.64 ms /   697 tokens (  182.76 ms per token,     5.47 tokens per second)\nllama_perf_context_print:        eval time =    4225.19 ms /    13 runs   (  325.01 ms per token,     3.08 tokens per second)\nllama_perf_context_print:       total time =  131613.57 ms /   710 tokens\n 55%|█████▍    | 100/183 [3:57:56<3:12:58, 139.50s/it]Llama.generate: 43 prefix-match hit, remaining 728 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  134243.27 ms /   728 tokens (  184.40 ms per token,     5.42 tokens per second)\nllama_perf_context_print:        eval time =    5582.94 ms /    17 runs   (  328.41 ms per token,     3.04 tokens per second)\nllama_perf_context_print:       total time =  139834.54 ms /   745 tokens\n 55%|█████▌    | 101/183 [4:00:16<3:10:47, 139.60s/it]Llama.generate: 43 prefix-match hit, remaining 747 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  137059.78 ms /   747 tokens (  183.48 ms per token,     5.45 tokens per second)\nllama_perf_context_print:        eval time =   10470.96 ms /    31 runs   (  337.77 ms per token,     2.96 tokens per second)\nllama_perf_context_print:       total time =  147546.31 ms /   778 tokens\n 56%|█████▌    | 102/183 [4:02:44<3:11:41, 141.99s/it]Llama.generate: 43 prefix-match hit, remaining 560 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  102387.59 ms /   560 tokens (  182.83 ms per token,     5.47 tokens per second)\nllama_perf_context_print:        eval time =    2902.08 ms /     9 runs   (  322.45 ms per token,     3.10 tokens per second)\nllama_perf_context_print:       total time =  105294.72 ms /   569 tokens\n 56%|█████▋    | 103/183 [4:04:29<2:54:38, 130.98s/it]Llama.generate: 43 prefix-match hit, remaining 740 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  136188.92 ms /   740 tokens (  184.04 ms per token,     5.43 tokens per second)\nllama_perf_context_print:        eval time =   25765.11 ms /    77 runs   (  334.61 ms per token,     2.99 tokens per second)\nllama_perf_context_print:       total time =  161992.56 ms /   817 tokens\n 57%|█████▋    | 104/183 [4:07:11<3:04:42, 140.29s/it]Llama.generate: 43 prefix-match hit, remaining 847 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  156956.24 ms /   847 tokens (  185.31 ms per token,     5.40 tokens per second)\nllama_perf_context_print:        eval time =    3649.80 ms /    11 runs   (  331.80 ms per token,     3.01 tokens per second)\nllama_perf_context_print:       total time =  160612.21 ms /   858 tokens\n 57%|█████▋    | 105/183 [4:09:51<3:10:18, 146.39s/it]Llama.generate: 43 prefix-match hit, remaining 818 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  151754.75 ms /   818 tokens (  185.52 ms per token,     5.39 tokens per second)\nllama_perf_context_print:        eval time =    2302.20 ms /     7 runs   (  328.89 ms per token,     3.04 tokens per second)\nllama_perf_context_print:       total time =  154061.17 ms /   825 tokens\n 58%|█████▊    | 106/183 [4:12:26<3:10:49, 148.69s/it]Llama.generate: 43 prefix-match hit, remaining 692 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  126504.08 ms /   692 tokens (  182.81 ms per token,     5.47 tokens per second)\nllama_perf_context_print:        eval time =    4883.65 ms /    15 runs   (  325.58 ms per token,     3.07 tokens per second)\nllama_perf_context_print:       total time =  131395.05 ms /   707 tokens\n 58%|█████▊    | 107/183 [4:14:37<3:01:46, 143.50s/it]Llama.generate: 43 prefix-match hit, remaining 668 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  122998.94 ms /   668 tokens (  184.13 ms per token,     5.43 tokens per second)\nllama_perf_context_print:        eval time =    5566.58 ms /    17 runs   (  327.45 ms per token,     3.05 tokens per second)\nllama_perf_context_print:       total time =  128574.12 ms /   685 tokens\n 59%|█████▉    | 108/183 [4:16:46<2:53:47, 139.03s/it]Llama.generate: 43 prefix-match hit, remaining 898 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  165278.40 ms /   898 tokens (  184.05 ms per token,     5.43 tokens per second)\nllama_perf_context_print:        eval time =    2015.80 ms /     6 runs   (  335.97 ms per token,     2.98 tokens per second)\nllama_perf_context_print:       total time =  167298.17 ms /   904 tokens\n 60%|█████▉    | 109/183 [4:19:33<3:01:55, 147.51s/it]Llama.generate: 43 prefix-match hit, remaining 698 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  128682.01 ms /   698 tokens (  184.36 ms per token,     5.42 tokens per second)\nllama_perf_context_print:        eval time =    1625.51 ms /     5 runs   (  325.10 ms per token,     3.08 tokens per second)\nllama_perf_context_print:       total time =  130310.95 ms /   703 tokens\n 60%|██████    | 110/183 [4:21:43<2:53:11, 142.35s/it]Llama.generate: 43 prefix-match hit, remaining 1480 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  275312.40 ms /  1480 tokens (  186.02 ms per token,     5.38 tokens per second)\nllama_perf_context_print:        eval time =    3216.81 ms /     9 runs   (  357.42 ms per token,     2.80 tokens per second)\nllama_perf_context_print:       total time =  278534.10 ms /  1489 tokens\n 61%|██████    | 111/183 [4:26:22<3:39:51, 183.21s/it]Llama.generate: 43 prefix-match hit, remaining 742 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  133557.86 ms /   742 tokens (  180.00 ms per token,     5.56 tokens per second)\nllama_perf_context_print:        eval time =    1947.32 ms /     6 runs   (  324.55 ms per token,     3.08 tokens per second)\nllama_perf_context_print:       total time =  135508.98 ms /   748 tokens\n 61%|██████    | 112/183 [4:28:37<3:19:52, 168.90s/it]Llama.generate: 43 prefix-match hit, remaining 601 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  107077.43 ms /   601 tokens (  178.17 ms per token,     5.61 tokens per second)\nllama_perf_context_print:        eval time =    1963.79 ms /     6 runs   (  327.30 ms per token,     3.06 tokens per second)\nllama_perf_context_print:       total time =  109044.87 ms /   607 tokens\n 62%|██████▏   | 113/183 [4:30:26<2:56:06, 150.95s/it]Llama.generate: 43 prefix-match hit, remaining 1610 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  296600.07 ms /  1610 tokens (  184.22 ms per token,     5.43 tokens per second)\nllama_perf_context_print:        eval time =    4281.57 ms /    12 runs   (  356.80 ms per token,     2.80 tokens per second)\nllama_perf_context_print:       total time =  300887.91 ms /  1622 tokens\n 62%|██████▏   | 114/183 [4:35:27<3:45:19, 195.93s/it]Llama.generate: 43 prefix-match hit, remaining 736 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  133731.56 ms /   736 tokens (  181.70 ms per token,     5.50 tokens per second)\nllama_perf_context_print:        eval time =    2334.76 ms /     7 runs   (  333.54 ms per token,     3.00 tokens per second)\nllama_perf_context_print:       total time =  136070.93 ms /   743 tokens\n 63%|██████▎   | 115/183 [4:37:43<3:21:42, 177.98s/it]Llama.generate: 43 prefix-match hit, remaining 321 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =   58359.42 ms /   321 tokens (  181.81 ms per token,     5.50 tokens per second)\nllama_perf_context_print:        eval time =    1650.79 ms /     5 runs   (  330.16 ms per token,     3.03 tokens per second)\nllama_perf_context_print:       total time =   60013.48 ms /   326 tokens\n 63%|██████▎   | 116/183 [4:38:43<2:39:13, 142.59s/it]Llama.generate: 43 prefix-match hit, remaining 784 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  141768.64 ms /   784 tokens (  180.83 ms per token,     5.53 tokens per second)\nllama_perf_context_print:        eval time =    4218.38 ms /    13 runs   (  324.49 ms per token,     3.08 tokens per second)\nllama_perf_context_print:       total time =  145993.58 ms /   797 tokens\n 64%|██████▍   | 117/183 [4:41:09<2:37:58, 143.61s/it]Llama.generate: 43 prefix-match hit, remaining 622 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  112801.76 ms /   622 tokens (  181.35 ms per token,     5.51 tokens per second)\nllama_perf_context_print:        eval time =    1958.38 ms /     6 runs   (  326.40 ms per token,     3.06 tokens per second)\nllama_perf_context_print:       total time =  114764.19 ms /   628 tokens\n 64%|██████▍   | 118/183 [4:43:04<2:26:12, 134.96s/it]Llama.generate: 43 prefix-match hit, remaining 842 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  151925.42 ms /   842 tokens (  180.43 ms per token,     5.54 tokens per second)\nllama_perf_context_print:        eval time =    4197.49 ms /    12 runs   (  349.79 ms per token,     2.86 tokens per second)\nllama_perf_context_print:       total time =  156129.18 ms /   854 tokens\n 65%|██████▌   | 119/183 [4:45:40<2:30:43, 141.31s/it]Llama.generate: 43 prefix-match hit, remaining 674 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  120934.02 ms /   674 tokens (  179.43 ms per token,     5.57 tokens per second)\nllama_perf_context_print:        eval time =    2614.62 ms /     8 runs   (  326.83 ms per token,     3.06 tokens per second)\nllama_perf_context_print:       total time =  123553.37 ms /   682 tokens\n 66%|██████▌   | 120/183 [4:47:44<2:22:47, 135.99s/it]Llama.generate: 43 prefix-match hit, remaining 678 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  123752.27 ms /   678 tokens (  182.53 ms per token,     5.48 tokens per second)\nllama_perf_context_print:        eval time =    2914.76 ms /     9 runs   (  323.86 ms per token,     3.09 tokens per second)\nllama_perf_context_print:       total time =  126671.88 ms /   687 tokens\n 66%|██████▌   | 121/183 [4:49:50<2:17:38, 133.19s/it]Llama.generate: 43 prefix-match hit, remaining 719 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  129948.56 ms /   719 tokens (  180.74 ms per token,     5.53 tokens per second)\nllama_perf_context_print:        eval time =    2253.99 ms /     7 runs   (  322.00 ms per token,     3.11 tokens per second)\nllama_perf_context_print:       total time =  132206.75 ms /   726 tokens\n 67%|██████▋   | 122/183 [4:52:03<2:15:06, 132.90s/it]Llama.generate: 43 prefix-match hit, remaining 699 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  125382.99 ms /   699 tokens (  179.37 ms per token,     5.57 tokens per second)\nllama_perf_context_print:        eval time =    3503.50 ms /    11 runs   (  318.50 ms per token,     3.14 tokens per second)\nllama_perf_context_print:       total time =  128892.27 ms /   710 tokens\n 67%|██████▋   | 123/183 [4:54:12<2:11:41, 131.70s/it]Llama.generate: 43 prefix-match hit, remaining 744 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  134228.61 ms /   744 tokens (  180.41 ms per token,     5.54 tokens per second)\nllama_perf_context_print:        eval time =    6223.69 ms /    19 runs   (  327.56 ms per token,     3.05 tokens per second)\nllama_perf_context_print:       total time =  140461.84 ms /   763 tokens\n 68%|██████▊   | 124/183 [4:56:32<2:12:05, 134.33s/it]Llama.generate: 43 prefix-match hit, remaining 1534 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  286090.74 ms /  1534 tokens (  186.50 ms per token,     5.36 tokens per second)\nllama_perf_context_print:        eval time =   11334.44 ms /    33 runs   (  343.47 ms per token,     2.91 tokens per second)\nllama_perf_context_print:       total time =  297440.82 ms /  1567 tokens\n 68%|██████▊   | 125/183 [5:01:29<2:57:09, 183.27s/it]Llama.generate: 43 prefix-match hit, remaining 673 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  123127.76 ms /   673 tokens (  182.95 ms per token,     5.47 tokens per second)\nllama_perf_context_print:        eval time =    2350.43 ms /     7 runs   (  335.78 ms per token,     2.98 tokens per second)\nllama_perf_context_print:       total time =  125482.45 ms /   680 tokens\n 69%|██████▉   | 126/183 [5:03:35<2:37:38, 165.93s/it]Llama.generate: 43 prefix-match hit, remaining 669 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  122191.41 ms /   669 tokens (  182.65 ms per token,     5.48 tokens per second)\nllama_perf_context_print:        eval time =    2979.73 ms /     9 runs   (  331.08 ms per token,     3.02 tokens per second)\nllama_perf_context_print:       total time =  125176.37 ms /   678 tokens\n 69%|██████▉   | 127/183 [5:05:40<2:23:27, 153.71s/it]Llama.generate: 43 prefix-match hit, remaining 779 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  140748.72 ms /   779 tokens (  180.68 ms per token,     5.53 tokens per second)\nllama_perf_context_print:        eval time =   14772.02 ms /    44 runs   (  335.73 ms per token,     2.98 tokens per second)\nllama_perf_context_print:       total time =  155541.69 ms /   823 tokens\n 70%|██████▉   | 128/183 [5:08:16<2:21:24, 154.26s/it]Llama.generate: 43 prefix-match hit, remaining 618 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  111751.24 ms /   618 tokens (  180.83 ms per token,     5.53 tokens per second)\nllama_perf_context_print:        eval time =   11588.59 ms /    36 runs   (  321.91 ms per token,     3.11 tokens per second)\nllama_perf_context_print:       total time =  123357.22 ms /   654 tokens\n 70%|███████   | 129/183 [5:10:19<2:10:29, 144.99s/it]Llama.generate: 43 prefix-match hit, remaining 779 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  140881.78 ms /   779 tokens (  180.85 ms per token,     5.53 tokens per second)\nllama_perf_context_print:        eval time =    8144.96 ms /    25 runs   (  325.80 ms per token,     3.07 tokens per second)\nllama_perf_context_print:       total time =  149039.07 ms /   804 tokens\n 71%|███████   | 130/183 [5:12:48<2:09:09, 146.21s/it]Llama.generate: 43 prefix-match hit, remaining 677 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  123936.65 ms /   677 tokens (  183.07 ms per token,     5.46 tokens per second)\nllama_perf_context_print:        eval time =    3296.59 ms /    10 runs   (  329.66 ms per token,     3.03 tokens per second)\nllama_perf_context_print:       total time =  127238.74 ms /   687 tokens\n 72%|███████▏  | 131/183 [5:14:55<2:01:46, 140.52s/it]Llama.generate: 43 prefix-match hit, remaining 681 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  123306.00 ms /   681 tokens (  181.07 ms per token,     5.52 tokens per second)\nllama_perf_context_print:        eval time =    1936.83 ms /     6 runs   (  322.80 ms per token,     3.10 tokens per second)\nllama_perf_context_print:       total time =  125246.51 ms /   687 tokens\n 72%|███████▏  | 132/183 [5:17:01<1:55:32, 135.94s/it]Llama.generate: 43 prefix-match hit, remaining 1248 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  229927.32 ms /  1248 tokens (  184.24 ms per token,     5.43 tokens per second)\nllama_perf_context_print:        eval time =    7769.66 ms /    23 runs   (  337.81 ms per token,     2.96 tokens per second)\nllama_perf_context_print:       total time =  237708.02 ms /  1271 tokens\n 73%|███████▎  | 133/183 [5:20:58<2:18:43, 166.47s/it]Llama.generate: 43 prefix-match hit, remaining 820 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  147187.07 ms /   820 tokens (  179.50 ms per token,     5.57 tokens per second)\nllama_perf_context_print:        eval time =    3573.00 ms /    11 runs   (  324.82 ms per token,     3.08 tokens per second)\nllama_perf_context_print:       total time =  150766.06 ms /   831 tokens\n 73%|███████▎  | 134/183 [5:23:29<2:12:06, 161.76s/it]Llama.generate: 44 prefix-match hit, remaining 727 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  131549.22 ms /   727 tokens (  180.95 ms per token,     5.53 tokens per second)\nllama_perf_context_print:        eval time =    4619.33 ms /    14 runs   (  329.95 ms per token,     3.03 tokens per second)\nllama_perf_context_print:       total time =  136175.68 ms /   741 tokens\n 74%|███████▍  | 135/183 [5:25:45<2:03:16, 154.09s/it]Llama.generate: 44 prefix-match hit, remaining 780 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  140742.04 ms /   780 tokens (  180.44 ms per token,     5.54 tokens per second)\nllama_perf_context_print:        eval time =    2256.08 ms /     7 runs   (  322.30 ms per token,     3.10 tokens per second)\nllama_perf_context_print:       total time =  143002.46 ms /   787 tokens\n 74%|███████▍  | 136/183 [5:28:08<1:58:05, 150.76s/it]Llama.generate: 43 prefix-match hit, remaining 699 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  125319.11 ms /   699 tokens (  179.28 ms per token,     5.58 tokens per second)\nllama_perf_context_print:        eval time =    2834.54 ms /     8 runs   (  354.32 ms per token,     2.82 tokens per second)\nllama_perf_context_print:       total time =  128158.21 ms /   707 tokens\n 75%|███████▍  | 137/183 [5:30:16<1:50:23, 143.99s/it]Llama.generate: 43 prefix-match hit, remaining 691 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  123872.76 ms /   691 tokens (  179.27 ms per token,     5.58 tokens per second)\nllama_perf_context_print:        eval time =    3846.16 ms /    11 runs   (  349.65 ms per token,     2.86 tokens per second)\nllama_perf_context_print:       total time =  127725.27 ms /   702 tokens\n 75%|███████▌  | 138/183 [5:32:24<1:44:19, 139.11s/it]Llama.generate: 43 prefix-match hit, remaining 542 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =   96924.56 ms /   542 tokens (  178.83 ms per token,     5.59 tokens per second)\nllama_perf_context_print:        eval time =    3044.59 ms /     9 runs   (  338.29 ms per token,     2.96 tokens per second)\nllama_perf_context_print:       total time =   99974.37 ms /   551 tokens\n 76%|███████▌  | 139/183 [5:34:04<1:33:24, 127.37s/it]Llama.generate: 43 prefix-match hit, remaining 1088 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  198529.86 ms /  1088 tokens (  182.47 ms per token,     5.48 tokens per second)\nllama_perf_context_print:        eval time = 1095428.59 ms /  2964 runs   (  369.58 ms per token,     2.71 tokens per second)\nllama_perf_context_print:       total time = 1302351.98 ms /  4052 tokens\n 77%|███████▋  | 140/183 [5:55:46<5:43:54, 479.87s/it]Llama.generate: 43 prefix-match hit, remaining 1491 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  272845.34 ms /  1491 tokens (  182.99 ms per token,     5.46 tokens per second)\nllama_perf_context_print:        eval time =    3067.94 ms /     9 runs   (  340.88 ms per token,     2.93 tokens per second)\nllama_perf_context_print:       total time =  275918.27 ms /  1500 tokens\n 77%|███████▋  | 141/183 [6:00:22<4:53:04, 418.69s/it]Llama.generate: 43 prefix-match hit, remaining 718 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  130704.61 ms /   718 tokens (  182.04 ms per token,     5.49 tokens per second)\nllama_perf_context_print:        eval time =    2266.57 ms /     7 runs   (  323.80 ms per token,     3.09 tokens per second)\nllama_perf_context_print:       total time =  132975.47 ms /   725 tokens\n 78%|███████▊  | 142/183 [6:02:35<3:47:31, 332.97s/it]Llama.generate: 43 prefix-match hit, remaining 679 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  124059.95 ms /   679 tokens (  182.71 ms per token,     5.47 tokens per second)\nllama_perf_context_print:        eval time =    3282.43 ms /    10 runs   (  328.24 ms per token,     3.05 tokens per second)\nllama_perf_context_print:       total time =  127348.14 ms /   689 tokens\n 78%|███████▊  | 143/183 [6:04:43<3:00:51, 271.29s/it]Llama.generate: 43 prefix-match hit, remaining 675 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  124716.48 ms /   675 tokens (  184.77 ms per token,     5.41 tokens per second)\nllama_perf_context_print:        eval time =    2284.80 ms /     7 runs   (  326.40 ms per token,     3.06 tokens per second)\nllama_perf_context_print:       total time =  127006.23 ms /   682 tokens\n 79%|███████▊  | 144/183 [6:06:50<2:28:12, 228.01s/it]Llama.generate: 43 prefix-match hit, remaining 739 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  135073.52 ms /   739 tokens (  182.78 ms per token,     5.47 tokens per second)\nllama_perf_context_print:        eval time =    1644.30 ms /     5 runs   (  328.86 ms per token,     3.04 tokens per second)\nllama_perf_context_print:       total time =  136721.19 ms /   744 tokens\n 79%|███████▉  | 145/183 [6:09:07<2:07:03, 200.62s/it]Llama.generate: 43 prefix-match hit, remaining 772 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  141651.59 ms /   772 tokens (  183.49 ms per token,     5.45 tokens per second)\nllama_perf_context_print:        eval time =    7303.39 ms /    21 runs   (  347.78 ms per token,     2.88 tokens per second)\nllama_perf_context_print:       total time =  148965.89 ms /   793 tokens\n 80%|███████▉  | 146/183 [6:11:35<1:54:09, 185.13s/it]Llama.generate: 43 prefix-match hit, remaining 755 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  139502.72 ms /   755 tokens (  184.77 ms per token,     5.41 tokens per second)\nllama_perf_context_print:        eval time =    3252.76 ms /    10 runs   (  325.28 ms per token,     3.07 tokens per second)\nllama_perf_context_print:       total time =  142760.92 ms /   765 tokens\n 80%|████████  | 147/183 [6:13:58<1:43:27, 172.42s/it]Llama.generate: 43 prefix-match hit, remaining 686 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  125287.17 ms /   686 tokens (  182.63 ms per token,     5.48 tokens per second)\nllama_perf_context_print:        eval time =    8041.11 ms /    25 runs   (  321.64 ms per token,     3.11 tokens per second)\nllama_perf_context_print:       total time =  133340.36 ms /   711 tokens\n 81%|████████  | 148/183 [6:16:12<1:33:44, 160.70s/it]Llama.generate: 43 prefix-match hit, remaining 575 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  103816.41 ms /   575 tokens (  180.55 ms per token,     5.54 tokens per second)\nllama_perf_context_print:        eval time =    4213.34 ms /    13 runs   (  324.10 ms per token,     3.09 tokens per second)\nllama_perf_context_print:       total time =  108036.61 ms /   588 tokens\n 81%|████████▏ | 149/183 [6:18:00<1:22:06, 144.90s/it]Llama.generate: 43 prefix-match hit, remaining 652 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  118499.99 ms /   652 tokens (  181.75 ms per token,     5.50 tokens per second)\nllama_perf_context_print:        eval time =    1589.39 ms /     5 runs   (  317.88 ms per token,     3.15 tokens per second)\nllama_perf_context_print:       total time =  120092.77 ms /   657 tokens\n 82%|████████▏ | 150/183 [6:20:00<1:15:36, 137.46s/it]Llama.generate: 43 prefix-match hit, remaining 737 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  133866.11 ms /   737 tokens (  181.64 ms per token,     5.51 tokens per second)\nllama_perf_context_print:        eval time =  838214.32 ms /  2367 runs   (  354.13 ms per token,     2.82 tokens per second)\nllama_perf_context_print:       total time =  977686.08 ms /  3104 tokens\n 83%|████████▎ | 151/183 [6:36:17<3:27:45, 389.53s/it]Llama.generate: 43 prefix-match hit, remaining 650 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  116358.71 ms /   650 tokens (  179.01 ms per token,     5.59 tokens per second)\nllama_perf_context_print:        eval time =    1584.64 ms /     5 runs   (  316.93 ms per token,     3.16 tokens per second)\nllama_perf_context_print:       total time =  117946.74 ms /   655 tokens\n 83%|████████▎ | 152/183 [6:38:15<2:39:09, 308.06s/it]Llama.generate: 43 prefix-match hit, remaining 699 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  127151.40 ms /   699 tokens (  181.90 ms per token,     5.50 tokens per second)\nllama_perf_context_print:        eval time =    2302.14 ms /     7 runs   (  328.88 ms per token,     3.04 tokens per second)\nllama_perf_context_print:       total time =  129457.64 ms /   706 tokens\n 84%|████████▎ | 153/183 [6:40:25<2:07:14, 254.48s/it]Llama.generate: 43 prefix-match hit, remaining 749 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  137509.09 ms /   749 tokens (  183.59 ms per token,     5.45 tokens per second)\nllama_perf_context_print:        eval time =    4469.55 ms /    13 runs   (  343.81 ms per token,     2.91 tokens per second)\nllama_perf_context_print:       total time =  141985.77 ms /   762 tokens\n 84%|████████▍ | 154/183 [6:42:47<1:46:41, 220.73s/it]Llama.generate: 43 prefix-match hit, remaining 749 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  136731.52 ms /   749 tokens (  182.55 ms per token,     5.48 tokens per second)\nllama_perf_context_print:        eval time =    2918.17 ms /     9 runs   (  324.24 ms per token,     3.08 tokens per second)\nllama_perf_context_print:       total time =  139654.71 ms /   758 tokens\n 85%|████████▍ | 155/183 [6:45:07<1:31:39, 196.41s/it]Llama.generate: 43 prefix-match hit, remaining 702 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  126861.17 ms /   702 tokens (  180.71 ms per token,     5.53 tokens per second)\nllama_perf_context_print:        eval time =    2627.18 ms /     8 runs   (  328.40 ms per token,     3.05 tokens per second)\nllama_perf_context_print:       total time =  129493.02 ms /   710 tokens\n 85%|████████▌ | 156/183 [6:47:16<1:19:21, 176.34s/it]Llama.generate: 43 prefix-match hit, remaining 687 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  123496.70 ms /   687 tokens (  179.76 ms per token,     5.56 tokens per second)\nllama_perf_context_print:        eval time =    3233.34 ms /    10 runs   (  323.33 ms per token,     3.09 tokens per second)\nllama_perf_context_print:       total time =  126735.46 ms /   697 tokens\n 86%|████████▌ | 157/183 [6:49:23<1:09:57, 161.46s/it]Llama.generate: 43 prefix-match hit, remaining 639 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  117218.34 ms /   639 tokens (  183.44 ms per token,     5.45 tokens per second)\nllama_perf_context_print:        eval time =    5105.40 ms /    16 runs   (  319.09 ms per token,     3.13 tokens per second)\nllama_perf_context_print:       total time =  122332.13 ms /   655 tokens\n 86%|████████▋ | 158/183 [6:51:25<1:02:23, 149.72s/it]Llama.generate: 43 prefix-match hit, remaining 855 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  155451.18 ms /   855 tokens (  181.81 ms per token,     5.50 tokens per second)\nllama_perf_context_print:        eval time =    2990.64 ms /     9 runs   (  332.29 ms per token,     3.01 tokens per second)\nllama_perf_context_print:       total time =  158446.72 ms /   864 tokens\n 87%|████████▋ | 159/183 [6:54:04<1:00:56, 152.34s/it]Llama.generate: 43 prefix-match hit, remaining 682 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  121509.06 ms /   682 tokens (  178.17 ms per token,     5.61 tokens per second)\nllama_perf_context_print:        eval time =    3091.20 ms /     9 runs   (  343.47 ms per token,     2.91 tokens per second)\nllama_perf_context_print:       total time =  124605.29 ms /   691 tokens\n 87%|████████▋ | 160/183 [6:56:08<55:12, 144.02s/it]  Llama.generate: 43 prefix-match hit, remaining 687 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  123678.31 ms /   687 tokens (  180.03 ms per token,     5.55 tokens per second)\nllama_perf_context_print:        eval time =    2581.88 ms /     8 runs   (  322.73 ms per token,     3.10 tokens per second)\nllama_perf_context_print:       total time =  126265.31 ms /   695 tokens\n 88%|████████▊ | 161/183 [6:58:14<50:51, 138.70s/it]Llama.generate: 43 prefix-match hit, remaining 752 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  135670.44 ms /   752 tokens (  180.41 ms per token,     5.54 tokens per second)\nllama_perf_context_print:        eval time =    5475.14 ms /    17 runs   (  322.07 ms per token,     3.10 tokens per second)\nllama_perf_context_print:       total time =  141154.18 ms /   769 tokens\n 89%|████████▊ | 162/183 [7:00:36<48:48, 139.44s/it]Llama.generate: 43 prefix-match hit, remaining 731 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  131341.89 ms /   731 tokens (  179.67 ms per token,     5.57 tokens per second)\nllama_perf_context_print:        eval time =    2283.18 ms /     7 runs   (  326.17 ms per token,     3.07 tokens per second)\nllama_perf_context_print:       total time =  133629.26 ms /   738 tokens\n 89%|████████▉ | 163/183 [7:02:49<45:53, 137.70s/it]Llama.generate: 43 prefix-match hit, remaining 676 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  122412.05 ms /   676 tokens (  181.08 ms per token,     5.52 tokens per second)\nllama_perf_context_print:        eval time =    3952.81 ms /    12 runs   (  329.40 ms per token,     3.04 tokens per second)\nllama_perf_context_print:       total time =  126371.26 ms /   688 tokens\n 90%|████████▉ | 164/183 [7:04:56<42:31, 134.30s/it]Llama.generate: 43 prefix-match hit, remaining 783 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  141249.22 ms /   783 tokens (  180.39 ms per token,     5.54 tokens per second)\nllama_perf_context_print:        eval time =    2587.77 ms /     8 runs   (  323.47 ms per token,     3.09 tokens per second)\nllama_perf_context_print:       total time =  143841.36 ms /   791 tokens\n 90%|█████████ | 165/183 [7:07:19<41:08, 137.17s/it]Llama.generate: 43 prefix-match hit, remaining 724 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  129804.58 ms /   724 tokens (  179.29 ms per token,     5.58 tokens per second)\nllama_perf_context_print:        eval time =   13037.86 ms /    39 runs   (  334.30 ms per token,     2.99 tokens per second)\nllama_perf_context_print:       total time =  142860.75 ms /   763 tokens\n 91%|█████████ | 166/183 [7:09:42<39:20, 138.88s/it]Llama.generate: 43 prefix-match hit, remaining 764 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  137969.73 ms /   764 tokens (  180.59 ms per token,     5.54 tokens per second)\nllama_perf_context_print:        eval time =    2239.16 ms /     7 runs   (  319.88 ms per token,     3.13 tokens per second)\nllama_perf_context_print:       total time =  140213.38 ms /   771 tokens\n 91%|█████████▏| 167/183 [7:12:03<37:08, 139.28s/it]Llama.generate: 43 prefix-match hit, remaining 680 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  122319.43 ms /   680 tokens (  179.88 ms per token,     5.56 tokens per second)\nllama_perf_context_print:        eval time =    2276.34 ms /     7 runs   (  325.19 ms per token,     3.08 tokens per second)\nllama_perf_context_print:       total time =  124600.05 ms /   687 tokens\n 92%|█████████▏| 168/183 [7:14:07<33:43, 134.88s/it]Llama.generate: 43 prefix-match hit, remaining 774 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  139324.42 ms /   774 tokens (  180.01 ms per token,     5.56 tokens per second)\nllama_perf_context_print:        eval time =    2225.53 ms /     7 runs   (  317.93 ms per token,     3.15 tokens per second)\nllama_perf_context_print:       total time =  141554.14 ms /   781 tokens\n 92%|█████████▏| 169/183 [7:16:29<31:56, 136.88s/it]Llama.generate: 43 prefix-match hit, remaining 657 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  118831.11 ms /   657 tokens (  180.87 ms per token,     5.53 tokens per second)\nllama_perf_context_print:        eval time =    2568.19 ms /     8 runs   (  321.02 ms per token,     3.12 tokens per second)\nllama_perf_context_print:       total time =  121404.01 ms /   665 tokens\n 93%|█████████▎| 170/183 [7:18:30<28:39, 132.24s/it]Llama.generate: 43 prefix-match hit, remaining 771 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  137169.49 ms /   771 tokens (  177.91 ms per token,     5.62 tokens per second)\nllama_perf_context_print:        eval time =    5467.89 ms /    16 runs   (  341.74 ms per token,     2.93 tokens per second)\nllama_perf_context_print:       total time =  142646.18 ms /   787 tokens\n 93%|█████████▎| 171/183 [7:20:53<27:04, 135.36s/it]Llama.generate: 43 prefix-match hit, remaining 706 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  125430.92 ms /   706 tokens (  177.66 ms per token,     5.63 tokens per second)\nllama_perf_context_print:        eval time =    2388.23 ms /     7 runs   (  341.18 ms per token,     2.93 tokens per second)\nllama_perf_context_print:       total time =  127823.99 ms /   713 tokens\n 94%|█████████▍| 172/183 [7:23:01<24:24, 133.11s/it]Llama.generate: 43 prefix-match hit, remaining 532 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =   96202.40 ms /   532 tokens (  180.83 ms per token,     5.53 tokens per second)\nllama_perf_context_print:        eval time =    4526.44 ms /    14 runs   (  323.32 ms per token,     3.09 tokens per second)\nllama_perf_context_print:       total time =  100736.02 ms /   546 tokens\n 95%|█████████▍| 173/183 [7:24:41<20:33, 123.40s/it]Llama.generate: 43 prefix-match hit, remaining 798 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  144433.03 ms /   798 tokens (  180.99 ms per token,     5.53 tokens per second)\nllama_perf_context_print:        eval time =    1943.54 ms /     6 runs   (  323.92 ms per token,     3.09 tokens per second)\nllama_perf_context_print:       total time =  146380.46 ms /   804 tokens\n 95%|█████████▌| 174/183 [7:27:08<19:32, 130.29s/it]Llama.generate: 43 prefix-match hit, remaining 620 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  112635.07 ms /   620 tokens (  181.67 ms per token,     5.50 tokens per second)\nllama_perf_context_print:        eval time =    1947.43 ms /     6 runs   (  324.57 ms per token,     3.08 tokens per second)\nllama_perf_context_print:       total time =  114586.26 ms /   626 tokens\n 96%|█████████▌| 175/183 [7:29:02<16:44, 125.58s/it]Llama.generate: 43 prefix-match hit, remaining 768 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  137790.42 ms /   768 tokens (  179.41 ms per token,     5.57 tokens per second)\nllama_perf_context_print:        eval time =    2577.94 ms /     8 runs   (  322.24 ms per token,     3.10 tokens per second)\nllama_perf_context_print:       total time =  140373.01 ms /   776 tokens\n 96%|█████████▌| 176/183 [7:31:23<15:10, 130.02s/it]Llama.generate: 43 prefix-match hit, remaining 674 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  121355.93 ms /   674 tokens (  180.05 ms per token,     5.55 tokens per second)\nllama_perf_context_print:        eval time =    3581.26 ms /    11 runs   (  325.57 ms per token,     3.07 tokens per second)\nllama_perf_context_print:       total time =  124942.83 ms /   685 tokens\n 97%|█████████▋| 177/183 [7:33:28<12:50, 128.50s/it]Llama.generate: 43 prefix-match hit, remaining 696 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  125297.76 ms /   696 tokens (  180.03 ms per token,     5.55 tokens per second)\nllama_perf_context_print:        eval time =    2897.41 ms /     9 runs   (  321.93 ms per token,     3.11 tokens per second)\nllama_perf_context_print:       total time =  128200.24 ms /   705 tokens\n 97%|█████████▋| 178/183 [7:35:36<10:42, 128.41s/it]Llama.generate: 43 prefix-match hit, remaining 620 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  109277.29 ms /   620 tokens (  176.25 ms per token,     5.67 tokens per second)\nllama_perf_context_print:        eval time =    2689.69 ms /     8 runs   (  336.21 ms per token,     2.97 tokens per second)\nllama_perf_context_print:       total time =  111971.84 ms /   628 tokens\n 98%|█████████▊| 179/183 [7:37:28<08:13, 123.48s/it]Llama.generate: 43 prefix-match hit, remaining 724 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  131113.15 ms /   724 tokens (  181.10 ms per token,     5.52 tokens per second)\nllama_perf_context_print:        eval time =    5527.39 ms /    17 runs   (  325.14 ms per token,     3.08 tokens per second)\nllama_perf_context_print:       total time =  136649.02 ms /   741 tokens\n 98%|█████████▊| 180/183 [7:39:44<06:22, 127.43s/it]Llama.generate: 43 prefix-match hit, remaining 626 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  111961.07 ms /   626 tokens (  178.85 ms per token,     5.59 tokens per second)\nllama_perf_context_print:        eval time =    1280.70 ms /     4 runs   (  320.17 ms per token,     3.12 tokens per second)\nllama_perf_context_print:       total time =  113244.95 ms /   630 tokens\n 99%|█████████▉| 181/183 [7:41:38<04:06, 123.18s/it]Llama.generate: 43 prefix-match hit, remaining 391 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =   69413.13 ms /   391 tokens (  177.53 ms per token,     5.63 tokens per second)\nllama_perf_context_print:        eval time =    2695.34 ms /     8 runs   (  336.92 ms per token,     2.97 tokens per second)\nllama_perf_context_print:       total time =   72113.26 ms /   399 tokens\n 99%|█████████▉| 182/183 [7:42:50<01:47, 107.86s/it]Llama.generate: 43 prefix-match hit, remaining 562 prompt tokens to eval\nllama_perf_context_print:        load time =  146424.35 ms\nllama_perf_context_print: prompt eval time =  102161.62 ms /   562 tokens (  181.78 ms per token,     5.50 tokens per second)\nllama_perf_context_print:        eval time =    3267.71 ms /    10 runs   (  326.77 ms per token,     3.06 tokens per second)\nllama_perf_context_print:       total time =  105434.82 ms /   572 tokens\n100%|██████████| 183/183 [7:44:35<00:00, 152.33s/it]\n2025-04-23 12:25:22,257 - BERTopic - Representation - Completed ✓\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"topic_info = topic_model.get_topic_info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T12:25:27.946861Z","iopub.execute_input":"2025-04-23T12:25:27.947084Z","iopub.status.idle":"2025-04-23T12:25:27.957442Z","shell.execute_reply.started":"2025-04-23T12:25:27.947067Z","shell.execute_reply":"2025-04-23T12:25:27.956748Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"topic_info.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T12:25:27.958465Z","iopub.execute_input":"2025-04-23T12:25:27.958677Z","iopub.status.idle":"2025-04-23T12:25:27.969839Z","shell.execute_reply.started":"2025-04-23T12:25:27.958661Z","shell.execute_reply":"2025-04-23T12:25:27.969092Z"}},"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"   Topic  Count                                               Name  \\\n0     -1  86524  -1_climate change_plant based_supply chain_far...   \n1      0   4451       0_soy sauce_olive oil_sesame oil_gluten free   \n2      1   3788  1_john deere_new holland_self propelled_massey...   \n3      2   3349  2_land management_environmental land_sustainab...   \n4      3   3079  3_dry matter_milk production_dm ha_body condition   \n\n                                      Representation  \\\n0  [climate change, plant based, supply chain, fa...   \n1  [soy sauce, olive oil, sesame oil, gluten free...   \n2  [john deere, new holland, self propelled, mass...   \n3  [land management, environmental land, sustaina...   \n4  [dry matter, milk production, dm ha, body cond...   \n\n                                                 LLM  \\\n0        [Sustainable Agriculture, , , , , , , , , ]   \n1  [[INST]\\n\\nShort Label: Asian Fusion Recipes, ...   \n2                  [Tractor Specs, , , , , , , , , ]   \n3  [Environmental Land Management Schemes, , , , ...   \n4  [Grass Silage and Dairy Farming, , , , , , , ,...   \n\n                                 Representative_Docs  \n0  [Although he has no data to show yields have i...  \n1  [Print Miso Satay Eggs Total Time 15 minutes S...  \n2  [Vital stats Valtra G135 HiTech Max power 135h...  \n3  [A 'lower-than-expected' level of interest in ...  \n4  [\"We need to calve the herd quickly and effici...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Topic</th>\n      <th>Count</th>\n      <th>Name</th>\n      <th>Representation</th>\n      <th>LLM</th>\n      <th>Representative_Docs</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-1</td>\n      <td>86524</td>\n      <td>-1_climate change_plant based_supply chain_far...</td>\n      <td>[climate change, plant based, supply chain, fa...</td>\n      <td>[Sustainable Agriculture, , , , , , , , , ]</td>\n      <td>[Although he has no data to show yields have i...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>4451</td>\n      <td>0_soy sauce_olive oil_sesame oil_gluten free</td>\n      <td>[soy sauce, olive oil, sesame oil, gluten free...</td>\n      <td>[[INST]\\n\\nShort Label: Asian Fusion Recipes, ...</td>\n      <td>[Print Miso Satay Eggs Total Time 15 minutes S...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>3788</td>\n      <td>1_john deere_new holland_self propelled_massey...</td>\n      <td>[john deere, new holland, self propelled, mass...</td>\n      <td>[Tractor Specs, , , , , , , , , ]</td>\n      <td>[Vital stats Valtra G135 HiTech Max power 135h...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>3349</td>\n      <td>2_land management_environmental land_sustainab...</td>\n      <td>[land management, environmental land, sustaina...</td>\n      <td>[Environmental Land Management Schemes, , , , ...</td>\n      <td>[A 'lower-than-expected' level of interest in ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3</td>\n      <td>3079</td>\n      <td>3_dry matter_milk production_dm ha_body condition</td>\n      <td>[dry matter, milk production, dm ha, body cond...</td>\n      <td>[Grass Silage and Dairy Farming, , , , , , , ,...</td>\n      <td>[\"We need to calve the herd quickly and effici...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"# Save the topic information to a CSV file\ntopic_info.to_csv('topic_info.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T12:25:27.970888Z","iopub.execute_input":"2025-04-23T12:25:27.971108Z","iopub.status.idle":"2025-04-23T12:25:27.994707Z","shell.execute_reply.started":"2025-04-23T12:25:27.971083Z","shell.execute_reply":"2025-04-23T12:25:27.994140Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"topic_model.get_topic(1, full=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T12:33:16.748955Z","iopub.execute_input":"2025-04-23T12:33:16.749644Z","iopub.status.idle":"2025-04-23T12:33:16.755321Z","shell.execute_reply.started":"2025-04-23T12:33:16.749617Z","shell.execute_reply":"2025-04-23T12:33:16.754693Z"}},"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"{'Main': [('john deere', 0.006787830532466935),\n  ('new holland', 0.005123795783297954),\n  ('self propelled', 0.0035550248731217086),\n  ('massey ferguson', 0.003355089055552476),\n  ('litre cylinder', 0.0033040858991294692),\n  ('wheel drive', 0.003288685160837065),\n  ('yes yes', 0.003129890573648985),\n  ('litres min', 0.002568013401614885),\n  ('disc coulters', 0.0025250179244172433),\n  ('second hand', 0.0025107869820325335)],\n 'LLM': [('Tractor Specs', 1),\n  ('', 0),\n  ('', 0),\n  ('', 0),\n  ('', 0),\n  ('', 0),\n  ('', 0),\n  ('', 0),\n  ('', 0),\n  ('', 0)]}"},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"fig1 = topic_model.visualize_topics()\nfig1.write_html(\"intertopic_distance_map2.html\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T12:34:46.636867Z","iopub.execute_input":"2025-04-23T12:34:46.637657Z","iopub.status.idle":"2025-04-23T12:34:54.651271Z","shell.execute_reply.started":"2025-04-23T12:34:46.637630Z","shell.execute_reply":"2025-04-23T12:34:54.650719Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"fig4 = topic_model.visualize_heatmap(n_clusters=20, top_n_topics=100)\nfig4.write_html(\"similarity_matrix.html\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T12:35:13.348989Z","iopub.execute_input":"2025-04-23T12:35:13.349700Z","iopub.status.idle":"2025-04-23T12:35:13.460722Z","shell.execute_reply.started":"2025-04-23T12:35:13.349676Z","shell.execute_reply":"2025-04-23T12:35:13.460191Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"fig3 = topic_model.visualize_hierarchy(top_n_topics=50, width=700)\nfig3.write_html(\"hierarchical_clustering.html\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T12:36:06.676848Z","iopub.execute_input":"2025-04-23T12:36:06.677587Z","iopub.status.idle":"2025-04-23T12:36:06.833654Z","shell.execute_reply.started":"2025-04-23T12:36:06.677565Z","shell.execute_reply":"2025-04-23T12:36:06.833082Z"}},"outputs":[],"execution_count":31}]}